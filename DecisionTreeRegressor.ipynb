{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=2)\n",
    "pd.set_option('precision', 2)\n",
    "np.set_printoptions(suppress=True)\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Size :  (1460, 80)\n",
      "Test Set Size :  (1459, 79)\n",
      "Train Features Size :  (1460, 79)\n",
      "Train Rows :  1460\n",
      "Test Rows :  1459\n"
     ]
    }
   ],
   "source": [
    "#1. Load training and test datasets\n",
    "train_path = 'data/train.csv'\n",
    "test_path = 'data/test.csv'\n",
    "train_data = pd.read_csv(train_path, index_col='Id')\n",
    "test_data = pd.read_csv(test_path, index_col='Id')\n",
    "\n",
    "#1a. Seperate features and target from training dataset.\n",
    "features = train_data.iloc[:,:-1]\n",
    "target = train_data.loc[:, ['SalePrice']]\n",
    "print('Train Set Size : ', train_data.shape)\n",
    "print('Test Set Size : ', test_data.shape)\n",
    "print('Train Features Size : ', features.shape)\n",
    "num_train_rows = train_data.shape[0]\n",
    "num_test_rows = test_data.shape[0]\n",
    "print('Train Rows : ', num_train_rows)\n",
    "print('Test Rows : ', num_test_rows)\n",
    "\n",
    "#1b. Merge training and test datasets to cover all \n",
    "#encodings for categorical features\n",
    "all_data = pd.concat((features, test_data)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Missing Ratio\n",
      "PoolQC                99.66\n",
      "MiscFeature           96.40\n",
      "Alley                 93.22\n",
      "Fence                 80.44\n",
      "FireplaceQu           48.65\n",
      "LotFrontage           16.65\n",
      "GarageFinish           5.45\n",
      "GarageQual             5.45\n",
      "GarageCond             5.45\n",
      "GarageYrBlt            5.45\n",
      "GarageType             5.38\n",
      "BsmtExposure           2.81\n",
      "BsmtCond               2.81\n",
      "BsmtQual               2.77\n",
      "BsmtFinType2           2.74\n",
      "BsmtFinType1           2.71\n",
      "MasVnrType             0.82\n",
      "MasVnrArea             0.79\n",
      "MSZoning               0.14\n",
      "BsmtFullBath           0.07\n",
      "BsmtHalfBath           0.07\n",
      "Functional             0.07\n",
      "Utilities              0.07\n",
      "GarageArea             0.03\n",
      "GarageCars             0.03\n",
      "Electrical             0.03\n",
      "KitchenQual            0.03\n",
      "TotalBsmtSF            0.03\n",
      "BsmtUnfSF              0.03\n",
      "BsmtFinSF2             0.03\n",
      "BsmtFinSF1             0.03\n",
      "Exterior2nd            0.03\n",
      "Exterior1st            0.03\n",
      "SaleType               0.03\n",
      "Empty DataFrame\n",
      "Columns: [Missing Ratio]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#3. Missing Data\n",
    "null_features = all_data.columns[all_data.isnull().any()]\n",
    "missing_ratio = (all_data[null_features].isnull().sum()/len(all_data)) * 100\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :missing_ratio})\n",
    "print(missing_data.sort_values(by='Missing Ratio',ascending=False))\n",
    "\n",
    "\n",
    "for col in ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu']:\n",
    "    all_data[col] = all_data[col].fillna('None')\n",
    "\n",
    "for col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'MasVnrType']:\n",
    "    all_data[col] = all_data[col].fillna('None')\n",
    "    \n",
    "for col in ['BsmtExposure', 'BsmtFinType2', 'BsmtQual', 'BsmtCond', 'BsmtFinType1']:\n",
    "    all_data[col] = all_data[col].fillna('None')\n",
    "\n",
    "'''\n",
    "No GarageYrBlt means no Garage. I can impute mean/median since it would \n",
    "incorrectly convey existence of Garage. same reasoning for MasVnrArea.\n",
    "'''\n",
    "for col in ['GarageYrBlt', 'MasVnrArea']:\n",
    "    all_data[col] = all_data[col].fillna(0)\n",
    "\n",
    "'''\n",
    "Group data by neighborhood & imputed null LotFrontage columns with median of\n",
    "grouped data.\n",
    "'''\n",
    "all_data['LotFrontage'] = all_data.groupby(['Neighborhood'])\\\n",
    "                    ['LotFrontage'].transform(lambda x : x.fillna(x.median()))\n",
    "    \n",
    "all_data['Electrical'] = \\\n",
    "    all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])\n",
    "    \n",
    "all_data['MSZoning'] = \\\n",
    "    all_data['MSZoning'].fillna(all_data['MSZoning'].mode()[0])\n",
    "    \n",
    "all_data['Utilities'] = all_data['Utilities'].fillna('ELO')\n",
    "\n",
    "all_data['Exterior1st'] = all_data['Exterior1st'].fillna('Other')\n",
    "\n",
    "all_data['Exterior2nd'] = all_data['Exterior2nd'].fillna('Other')\n",
    "\n",
    "all_data['SaleType'] = all_data['SaleType'].fillna('Oth')\n",
    "\n",
    "all_data['Functional'] = \\\n",
    "    all_data['Functional'].fillna(all_data['Functional'].mode()[0])\n",
    "\n",
    "all_data['KitchenQual'] = \\\n",
    "    all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])\n",
    "\n",
    "for col in ['BsmtFullBath', 'BsmtHalfBath', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'GarageCars', 'GarageArea']:\n",
    "    all_data[col] = all_data[col].fillna(0)\n",
    "    \n",
    "null_features = all_data.columns[all_data.isnull().any()]\n",
    "missing_ratio = (all_data[null_features].isnull().sum()/len(all_data)) * 100\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :missing_ratio})\n",
    "print(missing_data.sort_values(by='Missing Ratio',ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Model MAE 24112.539383561645\n",
      "Default Model MSE 1431596711.3784246\n",
      "R-squared -->  77.01998390916185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "            4. Try different parameter values for Decision Tree\n",
    "               and find optimal values\n",
    "               \n",
    "               Selecting following features based on analysis \n",
    "               from BackwardElimination_NumericFeatureOnly.ipynb\n",
    "'''\n",
    "\n",
    "final_num_features = all_data.loc[:,['MSSubClass', 'LotArea', 'OverallQual', \n",
    "                                     'OverallCond', 'YearBuilt', 'YearRemodAdd', \n",
    "                                       'BsmtFinSF1', 'TotalBsmtSF', 'GrLivArea', \n",
    "                                     'BsmtFullBath', 'FullBath', 'KitchenAbvGr', \n",
    "                                       'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', \n",
    "                                     'WoodDeckSF', 'EnclosedPorch', \n",
    "                               'ScreenPorch', 'PoolArea', 'YrSold']]\n",
    "\n",
    "final_num_features.insert(0, 'intercept', np.ones((2919,1)))\n",
    "final_train_num_features = final_num_features[:num_train_rows]\n",
    "final_test_num_features = final_num_features[num_train_rows:]\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train , X_test, y_train, y_test = \\\n",
    "    train_test_split(final_train_num_features, target, test_size=0.4, random_state=0)\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regressor = DecisionTreeRegressor(random_state=0)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "from sklearn import metrics\n",
    "y_train_predict = regressor.predict(X_test)\n",
    "print('Default Model MAE',metrics.mean_absolute_error(y_test, y_train_predict))\n",
    "print('Default Model MSE',metrics.mean_squared_error(y_test, y_train_predict))\n",
    "print(\"R-squared --> \", regressor.score(X_test, y_test)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for depth - 1 : 3394892163.9511614\n",
      "R-squared for depth - 1 : 45.505130087131185\n",
      "MSE for depth - 1 : 3394892163.9511614\n",
      "R-squared for depth - 1 : 45.505130087131185\n",
      "MSE for depth - 2 : 2357586901.2285194\n",
      "R-squared for depth - 2 : 62.15597277139908\n",
      "MSE for depth - 3 : 1849515473.9930742\n",
      "R-squared for depth - 3 : 70.31154443510023\n",
      "MSE for depth - 4 : 1454780810.443314\n",
      "R-squared for depth - 4 : 76.64783233509895\n",
      "MSE for depth - 5 : 1565750329.400996\n",
      "R-squared for depth - 5 : 74.86654762623375\n",
      "MSE for depth - 6 : 1699758536.1783252\n",
      "R-squared for depth - 6 : 72.71544548722264\n",
      "MSE for depth - 7 : 1536772051.8607423\n",
      "R-squared for depth - 7 : 75.3317074571184\n",
      "MSE for depth - 8 : 1444028317.618597\n",
      "R-squared for depth - 8 : 76.82043154279809\n",
      "MSE for depth - 9 : 1590962412.1827257\n",
      "R-squared for depth - 9 : 74.46184282117044\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "            4a. Tune Decision Tree Depth\n",
    "'''\n",
    "depth_list = np.linspace(1, 10, 10, endpoint=False, dtype=int)\n",
    "mse_list = []\n",
    "acc_list = []\n",
    "for depth in depth_list:\n",
    "    regressor = DecisionTreeRegressor(random_state=0, max_depth=depth)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    y_train_predict = regressor.predict(X_test)\n",
    "    mse = metrics.mean_squared_error(y_test, y_train_predict)\n",
    "    acc = regressor.score(X_test, y_test)*100\n",
    "    mse_list.append(mse)\n",
    "    acc_list.append(acc)\n",
    "    print(\"MSE for depth - {0} : {1}\".format(depth, mse))\n",
    "    print(\"R-squared for depth - {0} : {1}\".format(depth, acc))\n",
    "    \n",
    "# Best R-squared 76.82 is for depth 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for min_split - 0.01 : 1351162461.3300498\n",
      "R-squared for min_split - 0.01 : 78.31111593375726\n",
      "MSE for min_split - 0.020000000000000004 : 1446253086.823402\n",
      "R-squared for min_split - 0.020000000000000004 : 76.78471950761495\n",
      "MSE for min_split - 0.030000000000000006 : 1432206558.3096113\n",
      "R-squared for min_split - 0.030000000000000006 : 77.01019463528309\n",
      "MSE for min_split - 0.04000000000000001 : 1586058081.4139438\n",
      "R-squared for min_split - 0.04000000000000001 : 74.54056722664416\n",
      "MSE for min_split - 0.05000000000000001 : 1559960722.1241367\n",
      "R-squared for min_split - 0.05000000000000001 : 74.95948250609509\n",
      "MSE for min_split - 0.06000000000000001 : 1619647565.868082\n",
      "R-squared for min_split - 0.06000000000000001 : 74.00138821966262\n",
      "MSE for min_split - 0.07 : 1655441720.211563\n",
      "R-squared for min_split - 0.07 : 73.42681981207028\n",
      "MSE for min_split - 0.08 : 1695116098.933233\n",
      "R-squared for min_split - 0.08 : 72.78996597315628\n",
      "MSE for min_split - 0.09000000000000001 : 1693540777.133373\n",
      "R-squared for min_split - 0.09000000000000001 : 72.81525306694556\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "            4b. Tune Decision Tree min_samples_splits\n",
    "'''\n",
    "min_samples_splits = np.linspace(0.01, 0.1, 9, endpoint=False)\n",
    "sa_sp_mse_list = []\n",
    "sa_sp_acc_list = []\n",
    "for min_split in min_samples_splits:\n",
    "    regressor = DecisionTreeRegressor(random_state=0, min_samples_split=min_split)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    y_train_predict = regressor.predict(X_test)\n",
    "    mse = metrics.mean_squared_error(y_test, y_train_predict)\n",
    "    acc = regressor.score(X_test, y_test)*100\n",
    "    sa_sp_mse_list.append(mse)\n",
    "    sa_sp_acc_list.append(acc)\n",
    "    print(\"MSE for min_split - {0} : {1}\".format(min_split, mse))\n",
    "    print(\"R-squared for min_split - {0} : {1}\".format(min_split, acc))\n",
    "    \n",
    "# Best R-squared is 78.31 for min_samples_splits=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for min_leaf - 0.01 : 1649644762.6273823\n",
      "R-squared for min_leaf - 0.01 : 73.5198726791966\n",
      "MSE for min_leaf - 0.0325 : 1698408104.704687\n",
      "R-squared for min_leaf - 0.0325 : 72.73712263746135\n",
      "MSE for min_leaf - 0.05500000000000001 : 1972150104.5449157\n",
      "R-squared for min_leaf - 0.05500000000000001 : 68.34301114567836\n",
      "MSE for min_leaf - 0.0775 : 2045981050.45495\n",
      "R-squared for min_leaf - 0.0775 : 67.15787547756078\n",
      "MSE for min_leaf - 0.1 : 2329906714.11265\n",
      "R-squared for min_leaf - 0.1 : 62.60029563150653\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "            4c. Tune Decision Tree min_samples_leafs\n",
    "'''\n",
    "min_samples_leafs = np.linspace(0.01, 0.1, 5, endpoint=True)\n",
    "sa_lf_mse_list = []\n",
    "sa_lf_acc_list = []\n",
    "for min_sm_lf in min_samples_leafs:\n",
    "    regressor = DecisionTreeRegressor(random_state=0, min_samples_leaf=min_sm_lf)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    y_train_predict = regressor.predict(X_test)\n",
    "    mse = metrics.mean_squared_error(y_test, y_train_predict)\n",
    "    acc = regressor.score(X_test, y_test)*100\n",
    "    sa_lf_mse_list.append(mse)\n",
    "    sa_lf_acc_list.append(acc)\n",
    "    print(\"MSE for min_leaf - {0} : {1}\".format(min_sm_lf, mse))\n",
    "    print(\"R-squared for min_leaf - {0} : {1}\".format(min_sm_lf, acc))\n",
    "    \n",
    "# Best R-squared 73.51 is for min_leaf - 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for num_features - 1 : 2317143663.5753427\n",
      "R-squared for num_features - 1 : 62.8051683476733\n",
      "MSE for num_features - 2 : 1954134998.859589\n",
      "R-squared for num_features - 2 : 68.63218994529178\n",
      "MSE for num_features - 3 : 1975858021.5650685\n",
      "R-squared for num_features - 3 : 68.28349159515874\n",
      "MSE for num_features - 4 : 2137328767.515411\n",
      "R-squared for num_features - 4 : 65.69156028472305\n",
      "MSE for num_features - 5 : 2066363146.2363014\n",
      "R-squared for num_features - 5 : 66.83070171046722\n",
      "MSE for num_features - 6 : 1939005695.1506848\n",
      "R-squared for num_features - 6 : 68.87504579981456\n",
      "MSE for num_features - 7 : 1969003763.6386986\n",
      "R-squared for num_features - 7 : 68.3935162663436\n",
      "MSE for num_features - 8 : 1537799205.1472602\n",
      "R-squared for num_features - 8 : 75.31521957413827\n",
      "MSE for num_features - 9 : 2133284842.0171232\n",
      "R-squared for num_features - 9 : 65.75647344936097\n",
      "MSE for num_features - 10 : 1518675432.3321917\n",
      "R-squared for num_features - 10 : 75.62219471840544\n",
      "MSE for num_features - 11 : 1673843320.5633562\n",
      "R-squared for num_features - 11 : 73.13143699313783\n",
      "MSE for num_features - 12 : 2139982556.5342467\n",
      "R-squared for num_features - 12 : 65.64896161578937\n",
      "MSE for num_features - 13 : 1515881385.8955479\n",
      "R-squared for num_features - 13 : 75.66704480192568\n",
      "MSE for num_features - 14 : 2203031223.3835616\n",
      "R-squared for num_features - 14 : 64.63690328456558\n",
      "MSE for num_features - 15 : 1408143396.5582192\n",
      "R-squared for num_features - 15 : 77.39645693935823\n",
      "MSE for num_features - 16 : 1909928150.1010275\n",
      "R-squared for num_features - 16 : 69.34179907454082\n",
      "MSE for num_features - 17 : 1931272819.708904\n",
      "R-squared for num_features - 17 : 68.99917405511732\n",
      "MSE for num_features - 18 : 1296659835.1523972\n",
      "R-squared for num_features - 18 : 79.18599306682181\n",
      "MSE for num_features - 19 : 1358648735.0821917\n",
      "R-squared for num_features - 19 : 78.19094613320009\n",
      "MSE for num_features - 20 : 1737602194.083904\n",
      "R-squared for num_features - 20 : 72.1079784116878\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "            4d. Tune Decision Tree max_features\n",
    "'''\n",
    "max_features = list(range(1,X_train.shape[1]))\n",
    "mx_featutes_mse_list = []\n",
    "mx_featutes_acc_list = []\n",
    "for num_features in max_features:\n",
    "    regressor = DecisionTreeRegressor(random_state=0, max_features=num_features)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    y_train_predict = regressor.predict(X_test)\n",
    "    mse = metrics.mean_squared_error(y_test, y_train_predict)\n",
    "    acc = regressor.score(X_test, y_test)*100\n",
    "    mx_featutes_mse_list.append(mse)\n",
    "    mx_featutes_acc_list.append(acc)\n",
    "    print(\"MSE for num_features - {0} : {1}\".format(num_features, mse))\n",
    "    print(\"R-squared for num_features - {0} : {1}\".format(num_features, acc))\n",
    "    \n",
    "# Best R-squared is 79.18 is for max_features = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal params MAE 24634.73387314005\n",
      "Optimal params MSE 1634243258.518491\n",
      "Optimal params R-squared -->  73.76709789942265\n",
      "Adjusted Optimal params MAE 25017.204371393396\n",
      "Adjusted Optimal params MSE 1348170192.1797292\n",
      "Adjusted Optimal params R-squared -->  78.35914789183313\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "            5. Decision Tree Model by selecting optimal values for parameters\n",
    "'''\n",
    "regressor = DecisionTreeRegressor(random_state=0, max_depth=8, \n",
    "                        min_samples_split=0.01, min_samples_leaf=0.01, max_features = 18)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "from sklearn import metrics\n",
    "y_train_predict = regressor.predict(X_test)\n",
    "print('Optimal params MAE',metrics.mean_absolute_error(y_test, y_train_predict))\n",
    "print('Optimal params MSE',metrics.mean_squared_error(y_test, y_train_predict))\n",
    "print(\"Optimal params R-squared --> \", regressor.score(X_test, y_test)*100)\n",
    "\n",
    "\n",
    "'''\n",
    "Error with optimal parameters is higher than that with default parameters.\n",
    "So, after some trail and error, I decreased error by changing \n",
    "    max_features = 8\n",
    "    max_depth=6\n",
    "'''\n",
    "regressor = DecisionTreeRegressor(random_state=0, max_depth=6, \n",
    "                        min_samples_split=0.03, min_samples_leaf=0.01, max_features = 8)\n",
    "regressor.fit(X_train, y_train)\n",
    "y_train_predict = regressor.predict(X_test)\n",
    "print('Adjusted Optimal params MAE',metrics.mean_absolute_error(y_test, y_train_predict))\n",
    "print('Adjusted Optimal params MSE',metrics.mean_squared_error(y_test, y_train_predict))\n",
    "print(\"Adjusted Optimal params R-squared --> \", regressor.score(X_test, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth :  6\n",
      "Params :  <bound method BaseEstimator.get_params of DecisionTreeRegressor(criterion='mse', max_depth=6, max_features=8,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=0.01,\n",
      "           min_samples_split=0.03, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=0, splitter='best')>\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "            6. Visualize Decision Tree\n",
    "'''\n",
    "from sklearn.externals.six import StringIO\n",
    "from IPython.display import Image\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "dot_data = StringIO()\n",
    "export_graphviz(regressor, out_file=dot_data,\n",
    "               filled=True, rounded=True,\n",
    "               special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "graph.write_jpeg('DecisionTreeVisualization.jpeg')\n",
    "print('Max Depth : ', regressor.tree_.max_depth)\n",
    "print('Params : ', regressor.get_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
