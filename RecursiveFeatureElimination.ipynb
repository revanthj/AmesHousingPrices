{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=2)\n",
    "pd.set_option('precision', 2)\n",
    "np.set_printoptions(suppress=True)\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Size :  (1460, 80)\n",
      "Test Set Size :  (1459, 79)\n",
      "Train Features Size :  (1460, 79)\n",
      "Train Rows :  1460\n",
      "Test Rows :  1459\n"
     ]
    }
   ],
   "source": [
    "#1. Load training and test datasets\n",
    "train_path = 'data/train.csv'\n",
    "test_path = 'data/test.csv'\n",
    "train_data = pd.read_csv(train_path, index_col='Id')\n",
    "test_data = pd.read_csv(test_path, index_col='Id')\n",
    "\n",
    "#1a. Seperate features and target from training dataset.\n",
    "features = train_data.iloc[:,:-1]\n",
    "target = train_data.loc[:, ['SalePrice']]\n",
    "print('Train Set Size : ', train_data.shape)\n",
    "print('Test Set Size : ', test_data.shape)\n",
    "print('Train Features Size : ', features.shape)\n",
    "num_train_rows = train_data.shape[0]\n",
    "num_test_rows = test_data.shape[0]\n",
    "print('Train Rows : ', num_train_rows)\n",
    "print('Test Rows : ', num_test_rows)\n",
    "\n",
    "#1b. Merge training and test datasets to cover all \n",
    "#encodings for categorical features\n",
    "all_data = pd.concat((features, test_data)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness of SalePrice before Log Transform : 1.882876\n",
      "Kurtosis of SalePrice before Log Transform : 6.536282\n",
      "Skewness of SalePrice after Log Transform : 0.121335\n",
      "Kurtosis of SalePrice after Log Transform : 0.809532\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "2. In Numerical feature analysis, I found that SalPrice is NOT NORMALLY DISTRIBUTED.\n",
    "So, apply LOG TRANSFORMATION to bring SalePrice closer to Normal Distribution.\n",
    "'''\n",
    "print('Skewness of SalePrice before Log Transform : %f'% target.skew())\n",
    "print('Kurtosis of SalePrice before Log Transform : %f'% target.kurt())\n",
    "\n",
    "'''\n",
    "Skew = 1.882876 indicates positive skew with tail to the right.\n",
    "Kurt = 6.536282 indicates heavy tails i.e. more data on tails.\n",
    "'''\n",
    "\n",
    "#Apply Log transformation\n",
    "target['SalePrice'] = np.log(target['SalePrice'])\n",
    "print('Skewness of SalePrice after Log Transform : %f'% target.skew())\n",
    "print('Kurtosis of SalePrice after Log Transform : %f'% target.kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Missing Ratio\n",
      "PoolQC                99.66\n",
      "MiscFeature           96.40\n",
      "Alley                 93.22\n",
      "Fence                 80.44\n",
      "FireplaceQu           48.65\n",
      "LotFrontage           16.65\n",
      "GarageFinish           5.45\n",
      "GarageQual             5.45\n",
      "GarageCond             5.45\n",
      "GarageYrBlt            5.45\n",
      "GarageType             5.38\n",
      "BsmtExposure           2.81\n",
      "BsmtCond               2.81\n",
      "BsmtQual               2.77\n",
      "BsmtFinType2           2.74\n",
      "BsmtFinType1           2.71\n",
      "MasVnrType             0.82\n",
      "MasVnrArea             0.79\n",
      "MSZoning               0.14\n",
      "BsmtFullBath           0.07\n",
      "BsmtHalfBath           0.07\n",
      "Functional             0.07\n",
      "Utilities              0.07\n",
      "GarageArea             0.03\n",
      "GarageCars             0.03\n",
      "Electrical             0.03\n",
      "KitchenQual            0.03\n",
      "TotalBsmtSF            0.03\n",
      "BsmtUnfSF              0.03\n",
      "BsmtFinSF2             0.03\n",
      "BsmtFinSF1             0.03\n",
      "Exterior2nd            0.03\n",
      "Exterior1st            0.03\n",
      "SaleType               0.03\n",
      "Empty DataFrame\n",
      "Columns: [Missing Ratio]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#3. Missing Data\n",
    "null_features = all_data.columns[all_data.isnull().any()]\n",
    "missing_ratio = (all_data[null_features].isnull().sum()/len(all_data)) * 100\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :missing_ratio})\n",
    "print(missing_data.sort_values(by='Missing Ratio',ascending=False))\n",
    "\n",
    "\n",
    "for col in ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu']:\n",
    "    all_data[col] = all_data[col].fillna('None')\n",
    "\n",
    "for col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'MasVnrType']:\n",
    "    all_data[col] = all_data[col].fillna('None')\n",
    "    \n",
    "for col in ['BsmtExposure', 'BsmtFinType2', 'BsmtQual', 'BsmtCond', 'BsmtFinType1']:\n",
    "    all_data[col] = all_data[col].fillna('None')\n",
    "\n",
    "'''\n",
    "No GarageYrBlt means no Garage. I can impute mean/median since it would \n",
    "incorrectly convey existence of Garage. same reasoning for MasVnrArea.\n",
    "'''\n",
    "for col in ['GarageYrBlt', 'MasVnrArea']:\n",
    "    all_data[col] = all_data[col].fillna(0)\n",
    "\n",
    "'''\n",
    "Group data by neighborhood & imputed null LotFrontage columns with median of\n",
    "grouped data.\n",
    "'''\n",
    "all_data['LotFrontage'] = all_data.groupby(['Neighborhood'])\\\n",
    "                    ['LotFrontage'].transform(lambda x : x.fillna(x.median()))\n",
    "    \n",
    "all_data['Electrical'] = \\\n",
    "    all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])\n",
    "    \n",
    "all_data['MSZoning'] = \\\n",
    "    all_data['MSZoning'].fillna(all_data['MSZoning'].mode()[0])\n",
    "    \n",
    "all_data['Utilities'] = all_data['Utilities'].fillna('ELO')\n",
    "\n",
    "all_data['Exterior1st'] = all_data['Exterior1st'].fillna('Other')\n",
    "\n",
    "all_data['Exterior2nd'] = all_data['Exterior2nd'].fillna('Other')\n",
    "\n",
    "all_data['SaleType'] = all_data['SaleType'].fillna('Oth')\n",
    "\n",
    "all_data['Functional'] = \\\n",
    "    all_data['Functional'].fillna(all_data['Functional'].mode()[0])\n",
    "\n",
    "all_data['KitchenQual'] = \\\n",
    "    all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])\n",
    "\n",
    "for col in ['BsmtFullBath', 'BsmtHalfBath', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'GarageCars', 'GarageArea']:\n",
    "    all_data[col] = all_data[col].fillna(0)\n",
    "    \n",
    "null_features = all_data.columns[all_data.isnull().any()]\n",
    "missing_ratio = (all_data[null_features].isnull().sum()/len(all_data)) * 100\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :missing_ratio})\n",
    "print(missing_data.sort_values(by='Missing Ratio',ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 43  34  13   1   1   1   9 142   2  94 165   1   1   1 193   1  22 247\n",
      "  32  33 106  20  19  36 249   1   7  29  98  79 109  28  72 208 245 169\n",
      "   4 113 162 120   3 174 102 250 218  62 159 138 292 270  86 160 130 161\n",
      "  88   1 181 190  35  97 115  96 281 101  76 216 173  83 189 129 237  12\n",
      "  31 236  80  30  68  82 255  85  47  25  63 219  84 215  27  26 164 108\n",
      "  51  91  21 200 170  50 293 204 211 289 135 140  49   6  78 272 223 158\n",
      " 143 260  23  64 100 212  42 192  99 213 256 214 168 117 294 280 166  77\n",
      "   1 167  87 145 240 242 290 119 279 285  45  24 225 144  57 262 112   1\n",
      " 287 243 180 251  58 274 141 226 263 116 146 121 152 271 151 177 153 178\n",
      " 179 195  71 154 124 246  95 155 253 228 276 241 107 133 199 252  67  81\n",
      " 234   5 183 134 110  38 188 261 259  92  90 233 244 156 273 269  16 235\n",
      "  54 118 182 284  44 126 264 224  75 127  89 128 268  74 267 163 191 239\n",
      "  46  40 291 185  17 232 231 171 111  60  15 203 265 149 157 103  14 222\n",
      " 221 139 196  37 227 197  56  53  18 283 202 136   8 238 137  52  61 286\n",
      " 282 266 184 198 187 148 186 114  65  69 132 172 217 131  66  41 230  48\n",
      "  70 229 209 210 104 220 176 258 257 278 123 277 248  73 288 207 194 275\n",
      "  93 201 122 125  55 175 254  10 147  39  59 150 206 105  11 205]\n"
     ]
    }
   ],
   "source": [
    "#4. One Hot Encoding for Categorical Variables\n",
    "\n",
    "all_data = pd.get_dummies(all_data)\n",
    "\n",
    "#5. Standardize Features\n",
    "all_data_std = (all_data - all_data.mean())/all_data.std()\n",
    "\n",
    "train_data_features = all_data_std[:num_train_rows]\n",
    "test_data_features = all_data_std[num_train_rows:]\n",
    "\n",
    "#print(train_data_features.columns)\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import Ridge\n",
    "regressor = Ridge(alpha=0.05, normalize=True)\n",
    "rfe = RFE(regressor, 11)\n",
    "rfe = rfe.fit(train_data_features, target)\n",
    "#print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 0.10163147444173537\n",
      "MSE 0.029411021360469008\n",
      "Accuracy -->  80.52502621772013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Based on ranking, I picked following features\n",
    "OverallQual, OverallCond, YearBuilt, TotalBsmtSF, \n",
    "1stFlrSF, 2ndFlrSF, GrLivArea, GarageCars, Utilities_ELO, \n",
    "RoofMatl_ClyTile, Exterior1st_Other.\n",
    "\n",
    "Since TotalBsmtSF, 1stFlrSF, 2ndFlrSF are similar, I drop 1stFlrSF, 2ndFlrSF.\n",
    "\n",
    "Final Features:\n",
    "OverallQual, OverallCond, YearBuilt, TotalBsmtSF, \n",
    "GrLivArea, GarageCars, Utilities_ELO, \n",
    "RoofMatl_ClyTile, Exterior1st_Other.\n",
    "'''\n",
    "final_all_data_std = all_data_std.loc[:,['OverallQual', 'OverallCond', 'YearBuilt', \n",
    "                              'TotalBsmtSF', 'GrLivArea', 'GarageCars',\n",
    "                              'Utilities_ELO', 'RoofMatl_ClyTile', 'Exterior1st_Other']]\n",
    "\n",
    "train_data_std_features = final_all_data_std[:num_train_rows]\n",
    "test_data_std_features = final_all_data_std[num_train_rows:]\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train , X_test, y_train, y_test = train_test_split(train_data_std_features, target, test_size=0.4, random_state=0)\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import metrics\n",
    "regressor = Ridge()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "y_train_predict = regressor.predict(X_test)\n",
    "print('MAE',metrics.mean_absolute_error(y_test, y_train_predict))\n",
    "print('MSE',metrics.mean_squared_error(y_test, y_train_predict))\n",
    "print(\"Accuracy --> \", regressor.score(X_test, y_test)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
