{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=2)\n",
    "pd.set_option('precision', 2)\n",
    "np.set_printoptions(suppress=True)\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Size :  (1460, 80)\n",
      "Test Set Size :  (1459, 79)\n",
      "Train Features Size :  (1460, 79)\n",
      "Train Rows :  1460\n",
      "Test Rows :  1459\n"
     ]
    }
   ],
   "source": [
    "#1. Load training and test datasets\n",
    "train_path = 'data/train.csv'\n",
    "test_path = 'data/test.csv'\n",
    "train_data = pd.read_csv(train_path, index_col='Id')\n",
    "test_data = pd.read_csv(test_path, index_col='Id')\n",
    "\n",
    "#1a. Seperate features and target from training dataset.\n",
    "features = train_data.iloc[:,:-1]\n",
    "target = train_data.loc[:, ['SalePrice']]\n",
    "print('Train Set Size : ', train_data.shape)\n",
    "print('Test Set Size : ', test_data.shape)\n",
    "print('Train Features Size : ', features.shape)\n",
    "num_train_rows = train_data.shape[0]\n",
    "num_test_rows = test_data.shape[0]\n",
    "print('Train Rows : ', num_train_rows)\n",
    "print('Test Rows : ', num_test_rows)\n",
    "\n",
    "#1b. Merge training and test datasets to cover all \n",
    "#encodings for categorical features\n",
    "all_data = pd.concat((features, test_data)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness of SalePrice before Log Transform : 1.882876\n",
      "Kurtosis of SalePrice before Log Transform : 6.536282\n",
      "Skewness of SalePrice after Log Transform : 0.121335\n",
      "Kurtosis of SalePrice after Log Transform : 0.809532\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "2. In Numerical feature analysis, I found that SalPrice is NOT NORMALLY DISTRIBUTED.\n",
    "So, apply LOG TRANSFORMATION to bring SalePrice closer to Normal Distribution.\n",
    "'''\n",
    "print('Skewness of SalePrice before Log Transform : %f'% target.skew())\n",
    "print('Kurtosis of SalePrice before Log Transform : %f'% target.kurt())\n",
    "\n",
    "'''\n",
    "Skew = 1.882876 indicates positive skew with tail to the right.\n",
    "Kurt = 6.536282 indicates heavy tails i.e. more data on tails.\n",
    "'''\n",
    "\n",
    "#Apply Log transformation\n",
    "target['SalePrice'] = np.log(target['SalePrice'])\n",
    "print('Skewness of SalePrice after Log Transform : %f'% target.skew())\n",
    "print('Kurtosis of SalePrice after Log Transform : %f'% target.kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Missing Ratio\n",
      "PoolQC                99.66\n",
      "MiscFeature           96.40\n",
      "Alley                 93.22\n",
      "Fence                 80.44\n",
      "FireplaceQu           48.65\n",
      "LotFrontage           16.65\n",
      "GarageFinish           5.45\n",
      "GarageQual             5.45\n",
      "GarageCond             5.45\n",
      "GarageYrBlt            5.45\n",
      "GarageType             5.38\n",
      "BsmtExposure           2.81\n",
      "BsmtCond               2.81\n",
      "BsmtQual               2.77\n",
      "BsmtFinType2           2.74\n",
      "BsmtFinType1           2.71\n",
      "MasVnrType             0.82\n",
      "MasVnrArea             0.79\n",
      "MSZoning               0.14\n",
      "BsmtFullBath           0.07\n",
      "BsmtHalfBath           0.07\n",
      "Functional             0.07\n",
      "Utilities              0.07\n",
      "GarageArea             0.03\n",
      "GarageCars             0.03\n",
      "Electrical             0.03\n",
      "KitchenQual            0.03\n",
      "TotalBsmtSF            0.03\n",
      "BsmtUnfSF              0.03\n",
      "BsmtFinSF2             0.03\n",
      "BsmtFinSF1             0.03\n",
      "Exterior2nd            0.03\n",
      "Exterior1st            0.03\n",
      "SaleType               0.03\n",
      "Empty DataFrame\n",
      "Columns: [Missing Ratio]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#3. Missing Data\n",
    "null_features = all_data.columns[all_data.isnull().any()]\n",
    "missing_ratio = (all_data[null_features].isnull().sum()/len(all_data)) * 100\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :missing_ratio})\n",
    "print(missing_data.sort_values(by='Missing Ratio',ascending=False))\n",
    "\n",
    "\n",
    "for col in ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu']:\n",
    "    all_data[col] = all_data[col].fillna('None')\n",
    "\n",
    "for col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'MasVnrType']:\n",
    "    all_data[col] = all_data[col].fillna('None')\n",
    "    \n",
    "for col in ['BsmtExposure', 'BsmtFinType2', 'BsmtQual', 'BsmtCond', 'BsmtFinType1']:\n",
    "    all_data[col] = all_data[col].fillna('None')\n",
    "\n",
    "'''\n",
    "No GarageYrBlt means no Garage. I can impute mean/median since it would \n",
    "incorrectly convey existence of Garage. same reasoning for MasVnrArea.\n",
    "'''\n",
    "for col in ['GarageYrBlt', 'MasVnrArea']:\n",
    "    all_data[col] = all_data[col].fillna(0)\n",
    "\n",
    "'''\n",
    "Group data by neighborhood & imputed null LotFrontage columns with median of\n",
    "grouped data.\n",
    "'''\n",
    "all_data['LotFrontage'] = all_data.groupby(['Neighborhood'])\\\n",
    "                    ['LotFrontage'].transform(lambda x : x.fillna(x.median()))\n",
    "    \n",
    "all_data['Electrical'] = \\\n",
    "    all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])\n",
    "    \n",
    "all_data['MSZoning'] = \\\n",
    "    all_data['MSZoning'].fillna(all_data['MSZoning'].mode()[0])\n",
    "    \n",
    "all_data['Utilities'] = all_data['Utilities'].fillna('ELO')\n",
    "\n",
    "all_data['Exterior1st'] = all_data['Exterior1st'].fillna('Other')\n",
    "\n",
    "all_data['Exterior2nd'] = all_data['Exterior2nd'].fillna('Other')\n",
    "\n",
    "all_data['SaleType'] = all_data['SaleType'].fillna('Oth')\n",
    "\n",
    "all_data['Functional'] = \\\n",
    "    all_data['Functional'].fillna(all_data['Functional'].mode()[0])\n",
    "\n",
    "all_data['KitchenQual'] = \\\n",
    "    all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])\n",
    "\n",
    "for col in ['BsmtFullBath', 'BsmtHalfBath', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'GarageCars', 'GarageArea']:\n",
    "    all_data[col] = all_data[col].fillna(0)\n",
    "    \n",
    "null_features = all_data.columns[all_data.isnull().any()]\n",
    "missing_ratio = (all_data[null_features].isnull().sum()/len(all_data)) * 100\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :missing_ratio})\n",
    "print(missing_data.sort_values(by='Missing Ratio',ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness of OverallQual before Log Transform : 0.197212\n",
      "Kurtosis of OverallQual before Log Transform : 0.067219\n",
      "Skewness of GarageCars before Log Transform : -0.219694\n",
      "Kurtosis of GarageCars before Log Transform : 0.236592\n",
      "Skewness of YearBuilt before Log Transform : -0.600114\n",
      "Kurtosis of YearBuilt before Log Transform : -0.511317\n",
      "Skewness of FullBath before Log Transform : 0.167692\n",
      "Kurtosis of FullBath before Log Transform : -0.538129\n",
      "Skewness of TotalBsmtSF before Log Transform : 1.157489\n",
      "Kurtosis of TotalBsmtSF before Log Transform : 9.122827\n",
      "Skewness of YearRemodAdd before Log Transform : -0.451252\n",
      "Kurtosis of YearRemodAdd before Log Transform : -1.346431\n",
      "Skewness of TotRmsAbvGrd before Log Transform : 0.758757\n",
      "Kurtosis of TotRmsAbvGrd before Log Transform : 1.169064\n",
      "Skewness of Fireplaces before Log Transform : 0.733872\n",
      "Kurtosis of Fireplaces before Log Transform : 0.076424\n",
      "Skewness of LotArea before Log Transform : 12.829025\n",
      "Kurtosis of LotArea before Log Transform : 264.952310\n",
      "Skewness of MSSubClass before Log Transform : 1.376165\n",
      "Kurtosis of MSSubClass before Log Transform : 1.457827\n",
      "Skewness of OverallCond before Log Transform : 0.570605\n",
      "Kurtosis of OverallCond before Log Transform : 1.479447\n",
      "Skewness of BsmtFinSF1 before Log Transform : 1.425963\n",
      "Kurtosis of BsmtFinSF1 before Log Transform : 6.904047\n",
      "Skewness of EnclosedPorch before Log Transform : 4.005950\n",
      "Kurtosis of EnclosedPorch before Log Transform : 28.377909\n",
      "Skewness of ScreenPorch before Log Transform : 3.948723\n",
      "Kurtosis of ScreenPorch before Log Transform : 17.776704\n",
      "Skewness of YrSold before Log Transform : 0.132467\n",
      "Kurtosis of YrSold before Log Transform : -1.155147\n",
      "Skewness of GrLivArea before Log Transform : 1.270010\n",
      "Kurtosis of GrLivArea before Log Transform : 4.121604\n",
      "Skewness of KitchenAbvGr before Log Transform : 4.304467\n",
      "Kurtosis of KitchenAbvGr before Log Transform : 19.777937\n",
      "Skewness of WoodDeckSF before Log Transform : 1.843380\n",
      "Kurtosis of WoodDeckSF before Log Transform : 6.741550\n",
      "Skewness of BsmtFullBath before Log Transform : 0.625153\n",
      "Kurtosis of BsmtFullBath before Log Transform : -0.734512\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "                    4.Numerical Features - Analysis\n",
    "                    \n",
    "Linear models assume normal distribution of the features. So, lets check if they \n",
    "follow normal distribution or apply transformation to correct them.\n",
    "\n",
    "Selecting following features based on analysis \n",
    "from BackwardElimination_NumericFeatureOnly.ipynb\n",
    "'''\n",
    "print('Skewness of OverallQual before Log Transform : %f'% all_data['OverallQual'].skew())\n",
    "print('Kurtosis of OverallQual before Log Transform : %f'% all_data['OverallQual'].kurt())\n",
    "\n",
    "print('Skewness of GarageCars before Log Transform : %f'% all_data['GarageCars'].skew())\n",
    "print('Kurtosis of GarageCars before Log Transform : %f'% all_data['GarageCars'].kurt())\n",
    "\n",
    "print('Skewness of YearBuilt before Log Transform : %f'% all_data['YearBuilt'].skew())\n",
    "print('Kurtosis of YearBuilt before Log Transform : %f'% all_data['YearBuilt'].kurt())\n",
    "\n",
    "print('Skewness of FullBath before Log Transform : %f'% all_data['FullBath'].skew())\n",
    "print('Kurtosis of FullBath before Log Transform : %f'% all_data['FullBath'].kurt())\n",
    "\n",
    "print('Skewness of TotalBsmtSF before Log Transform : %f'% all_data['TotalBsmtSF'].skew())\n",
    "print('Kurtosis of TotalBsmtSF before Log Transform : %f'% all_data['TotalBsmtSF'].kurt())\n",
    "\n",
    "print('Skewness of YearRemodAdd before Log Transform : %f'% all_data['YearRemodAdd'].skew())\n",
    "print('Kurtosis of YearRemodAdd before Log Transform : %f'% all_data['YearRemodAdd'].kurt())\n",
    "\n",
    "print('Skewness of TotRmsAbvGrd before Log Transform : %f'% all_data['TotRmsAbvGrd'].skew())\n",
    "print('Kurtosis of TotRmsAbvGrd before Log Transform : %f'% all_data['TotRmsAbvGrd'].kurt())\n",
    "\n",
    "print('Skewness of Fireplaces before Log Transform : %f'% all_data['Fireplaces'].skew())\n",
    "print('Kurtosis of Fireplaces before Log Transform : %f'% all_data['Fireplaces'].kurt())\n",
    "\n",
    "print('Skewness of LotArea before Log Transform : %f'% all_data['LotArea'].skew())\n",
    "print('Kurtosis of LotArea before Log Transform : %f'% all_data['LotArea'].kurt())\n",
    "\n",
    "print('Skewness of MSSubClass before Log Transform : %f'% all_data['MSSubClass'].skew())\n",
    "print('Kurtosis of MSSubClass before Log Transform : %f'% all_data['MSSubClass'].kurt())\n",
    "\n",
    "print('Skewness of OverallCond before Log Transform : %f'% all_data['OverallCond'].skew())\n",
    "print('Kurtosis of OverallCond before Log Transform : %f'% all_data['OverallCond'].kurt())\n",
    "\n",
    "print('Skewness of BsmtFinSF1 before Log Transform : %f'% all_data['BsmtFinSF1'].skew())\n",
    "print('Kurtosis of BsmtFinSF1 before Log Transform : %f'% all_data['BsmtFinSF1'].kurt())\n",
    "\n",
    "print('Skewness of EnclosedPorch before Log Transform : %f'% all_data['EnclosedPorch'].skew())\n",
    "print('Kurtosis of EnclosedPorch before Log Transform : %f'% all_data['EnclosedPorch'].kurt())\n",
    "\n",
    "print('Skewness of ScreenPorch before Log Transform : %f'% all_data['ScreenPorch'].skew())\n",
    "print('Kurtosis of ScreenPorch before Log Transform : %f'% all_data['ScreenPorch'].kurt())\n",
    "\n",
    "print('Skewness of YrSold before Log Transform : %f'% all_data['YrSold'].skew())\n",
    "print('Kurtosis of YrSold before Log Transform : %f'% all_data['YrSold'].kurt())\n",
    "\n",
    "print('Skewness of GrLivArea before Log Transform : %f'% all_data['GrLivArea'].skew())\n",
    "print('Kurtosis of GrLivArea before Log Transform : %f'% all_data['GrLivArea'].kurt())\n",
    "\n",
    "print('Skewness of KitchenAbvGr before Log Transform : %f'% all_data['KitchenAbvGr'].skew())\n",
    "print('Kurtosis of KitchenAbvGr before Log Transform : %f'% all_data['KitchenAbvGr'].kurt())\n",
    "\n",
    "print('Skewness of WoodDeckSF before Log Transform : %f'% all_data['WoodDeckSF'].skew())\n",
    "print('Kurtosis of WoodDeckSF before Log Transform : %f'% all_data['WoodDeckSF'].kurt())\n",
    "\n",
    "print('Skewness of BsmtFullBath before Log Transform : %f'% all_data['BsmtFullBath'].skew())\n",
    "print('Kurtosis of BsmtFullBath before Log Transform : %f'% all_data['BsmtFullBath'].kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness of TotalBsmtSF after Log Transform : -0.424181\n",
      "Kurtosis of TotalBsmtSF after Log Transform : 1.712836\n",
      "Skewness of TotalBsmtSF after Log Transform : -0.742638\n",
      "Kurtosis of TotalBsmtSF after Log Transform : 2.775776\n",
      "Skewness of LotArea after Log Transform : -0.505542\n",
      "Kurtosis of LotArea after Log Transform : 3.754157\n",
      "Skewness of MSSubClass after Log Transform : 0.229245\n",
      "Kurtosis of MSSubClass after Log Transform : -1.145834\n",
      "Skewness of OverallCond after Log Transform : -1.408074\n",
      "Kurtosis of OverallCond after Log Transform : 11.127618\n",
      "Skewness of GrLivArea after Log Transform : 0.012386\n",
      "Kurtosis of GrLivArea after Log Transform : 0.212402\n",
      "Skewness of BsmtFinSF1 after Log Transform : -1.845559\n",
      "Kurtosis of BsmtFinSF1 after Log Transform : 6.243265\n",
      "Skewness of EnclosedPorch after Log Transform : 2.342653\n",
      "Kurtosis of EnclosedPorch after Log Transform : 4.062502\n",
      "Skewness of ScreenPorch after Log Transform : 3.057237\n",
      "Kurtosis of ScreenPorch after Log Transform : 7.673697\n",
      "Skewness of KitchenAbvGr after Log Transform : 4.451051\n",
      "Kurtosis of KitchenAbvGr after Log Transform : 18.119131\n",
      "Skewness of WoodDeckSF after Log Transform : 0.550886\n",
      "Kurtosis of WoodDeckSF after Log Transform : 2.303272\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "MSSubClass, OverallCond, BsmtFinSF1, EnclosedPorch, ScreenPorch, \n",
    "PoolArea, GrLivArea, KitchenAbvGr, WoodDeckSF\n",
    "These features has high Skewness & Kurtosis\n",
    "'''\n",
    "TotalBsmtSFMean = all_data['TotalBsmtSF'].mean()\n",
    "all_data.loc[all_data['TotalBsmtSF'] == 0, 'TotalBsmtSF'] = np.round(TotalBsmtSFMean).astype(int)\n",
    "all_data['TotalBsmtSF'] = np.log(all_data['TotalBsmtSF'])\n",
    "print('Skewness of TotalBsmtSF after Log Transform : %f'% all_data['TotalBsmtSF'].skew())\n",
    "print('Kurtosis of TotalBsmtSF after Log Transform : %f'% all_data['TotalBsmtSF'].kurt())\n",
    "\n",
    "OpenPorchSFMean = all_data['OpenPorchSF'].mean()\n",
    "all_data.loc[all_data['OpenPorchSF'] == 0, 'OpenPorchSF'] = np.round(OpenPorchSFMean).astype(int)\n",
    "all_data['TotalBsmtSF'] = np.log(all_data['TotalBsmtSF'])\n",
    "print('Skewness of TotalBsmtSF after Log Transform : %f'% all_data['TotalBsmtSF'].skew())\n",
    "print('Kurtosis of TotalBsmtSF after Log Transform : %f'% all_data['TotalBsmtSF'].kurt())\n",
    "\n",
    "all_data['LotArea'] = np.log(all_data['LotArea'])\n",
    "print('Skewness of LotArea after Log Transform : %f'% all_data['LotArea'].skew())\n",
    "print('Kurtosis of LotArea after Log Transform : %f'% all_data['LotArea'].kurt())\n",
    "\n",
    "all_data['MSSubClass'] = np.log(all_data['MSSubClass'])\n",
    "print('Skewness of MSSubClass after Log Transform : %f'% all_data['MSSubClass'].skew())\n",
    "print('Kurtosis of MSSubClass after Log Transform : %f'% all_data['MSSubClass'].kurt())\n",
    "\n",
    "all_data['OverallCond'] = np.log(all_data['OverallCond'])\n",
    "print('Skewness of OverallCond after Log Transform : %f'% all_data['OverallCond'].skew())\n",
    "print('Kurtosis of OverallCond after Log Transform : %f'% all_data['OverallCond'].kurt())\n",
    "\n",
    "all_data['GrLivArea'] = np.log(all_data['GrLivArea'])\n",
    "print('Skewness of GrLivArea after Log Transform : %f'% all_data['GrLivArea'].skew())\n",
    "print('Kurtosis of GrLivArea after Log Transform : %f'% all_data['GrLivArea'].kurt())\n",
    "\n",
    "BsmtSF1Mean = all_data['BsmtFinSF1'].mean()\n",
    "all_data.loc[all_data['BsmtFinSF1'] == 0, 'BsmtFinSF1'] = np.round(BsmtSF1Mean).astype(int)\n",
    "all_data['BsmtFinSF1'] = np.log(all_data['BsmtFinSF1'])\n",
    "print('Skewness of BsmtFinSF1 after Log Transform : %f'% all_data['BsmtFinSF1'].skew())\n",
    "print('Kurtosis of BsmtFinSF1 after Log Transform : %f'% all_data['BsmtFinSF1'].kurt())\n",
    "\n",
    "EnclosedPorchMean = all_data['EnclosedPorch'].mean()\n",
    "all_data.loc[all_data['EnclosedPorch'] == 0, 'EnclosedPorch'] = np.round(EnclosedPorchMean).astype(int)\n",
    "all_data['EnclosedPorch'] = np.log(all_data['EnclosedPorch'])\n",
    "print('Skewness of EnclosedPorch after Log Transform : %f'% all_data['EnclosedPorch'].skew())\n",
    "print('Kurtosis of EnclosedPorch after Log Transform : %f'% all_data['EnclosedPorch'].kurt())\n",
    "\n",
    "ScreenPorchMean = all_data['ScreenPorch'].mean()\n",
    "all_data.loc[all_data['ScreenPorch'] == 0, 'ScreenPorch'] = np.round(ScreenPorchMean).astype(int)\n",
    "all_data['ScreenPorch'] = np.log(all_data['ScreenPorch'])\n",
    "print('Skewness of ScreenPorch after Log Transform : %f'% all_data['ScreenPorch'].skew())\n",
    "print('Kurtosis of ScreenPorch after Log Transform : %f'% all_data['ScreenPorch'].kurt())\n",
    "\n",
    "KitchenAbvGrMean = all_data['KitchenAbvGr'].mean()\n",
    "all_data.loc[all_data['KitchenAbvGr'] == 0, 'KitchenAbvGr'] = np.round(KitchenAbvGrMean).astype(int)\n",
    "all_data['KitchenAbvGr'] = np.log(all_data['KitchenAbvGr'])\n",
    "print('Skewness of KitchenAbvGr after Log Transform : %f'% all_data['KitchenAbvGr'].skew())\n",
    "print('Kurtosis of KitchenAbvGr after Log Transform : %f'% all_data['KitchenAbvGr'].kurt())\n",
    "\n",
    "WoodDeckSFMean = all_data['WoodDeckSF'].mean()\n",
    "all_data.loc[all_data['WoodDeckSF'] == 0, 'WoodDeckSF'] = np.round(WoodDeckSFMean).astype(int)\n",
    "all_data['WoodDeckSF'] = np.log(all_data['WoodDeckSF'])\n",
    "print('Skewness of WoodDeckSF after Log Transform : %f'% all_data['WoodDeckSF'].skew())\n",
    "print('Kurtosis of WoodDeckSF after Log Transform : %f'% all_data['WoodDeckSF'].kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression R-squared -->  87.67028488430935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "            5. LinearRegression Model\n",
    "'''\n",
    "final_features = all_data.loc[:,['MSSubClass', 'LotArea', 'OverallQual', \n",
    "                                     'OverallCond', 'YearBuilt', 'YearRemodAdd', \n",
    "                                       'BsmtFinSF1', 'TotalBsmtSF', 'GrLivArea', \n",
    "                                     'BsmtFullBath', 'FullBath', 'KitchenAbvGr', \n",
    "                                       'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', \n",
    "                                     'WoodDeckSF', 'EnclosedPorch', \n",
    "                               'ScreenPorch',  'YrSold']]\n",
    "\n",
    "train_selected_features = final_features[:num_train_rows]\n",
    "test_selected_features = final_features[num_train_rows:]\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train , X_test, y_train, y_test = train_test_split(train_selected_features, target, test_size=0.4, random_state=0)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "y_train_predict = regressor.predict(X_test)\n",
    "print(\"LinearRegression R-squared --> \", regressor.score(X_test, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO Regression R-squared -->  87.52486439090472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "            6. LASSO Regression with K-Fold\n",
    "'''\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import KFold, cross_val_predict, cross_val_score\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "lasso = make_pipeline(RobustScaler(), LassoCV(alphas=[0.002], random_state=0, cv=kf))\n",
    "lasso.fit(X_train, y_train)\n",
    "print(\"LASSO Regression R-squared --> \", lasso.score(X_test, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RIDGE Regression R-squared -->  87.70744067789894\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "            7. RIDGE Regression with K-Fold\n",
    "'''\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "ridge = make_pipeline(RobustScaler(), RidgeCV(alphas=[2.5], cv=kf))\n",
    "ridge.fit(X_train, y_train)\n",
    "print(\"RIDGE Regression R-squared --> \", ridge.score(X_test, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet R-squared -->  87.58773038070525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "            8. ElasticNet Regression with K-Fold\n",
    "'''\n",
    "from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "ENet = make_pipeline(RobustScaler(), ElasticNetCV(alphas=[0.003], cv=kf, random_state=0))\n",
    "ENet.fit(X_train, y_train)\n",
    "print(\"ElasticNet R-squared --> \", ENet.score(X_test, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest R-squared -->  88.62647758122908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "            9. RANDOM FOREST Model\n",
    "'''\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_regr = RandomForestRegressor(random_state=0, n_estimators=70,\n",
    "                        min_samples_split=2, min_samples_leaf=1, max_features='sqrt',\n",
    "                        max_depth=10, bootstrap=False)\n",
    "forest_regr.fit(X_train, y_train)\n",
    "print(\"Random Forest R-squared --> \", forest_regr.score(X_test, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "            10. Code that calculates simple average of 4 model scores\n",
    "'''\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "class AverageModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Average of 4 Models R-squared -->  89.02307039389127\n",
      "MSE of average of 4 Models 0.016577311719483807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:14: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "            11.Simple Average of 4 Models \n",
    "'''\n",
    "average_models = make_pipeline(RobustScaler(), AverageModels(models = (ENet, ridge, lasso, forest_regr)))\n",
    "average_models.fit(X_train, y_train)\n",
    "y_predict = average_models.predict(X_test)\n",
    "print(\"Simple Average of 4 Models R-squared --> \", average_models.score(X_test, y_test)*100)\n",
    "\n",
    "from sklearn import metrics\n",
    "print('MSE of average of 4 Models',metrics.mean_squared_error(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "            12. Stacked Model code\n",
    "'''\n",
    "\n",
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=0)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y.iloc[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred.flatten()\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:24: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:24: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:24: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:24: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Model R-squared -->  0.8885636917904103\n",
      "MSE of Stacked Model 0.016829063174740595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:24: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "            13. Stacked Model\n",
    "'''\n",
    "from sklearn import metrics\n",
    "\n",
    "stacked_averaged_models = make_pipeline(RobustScaler(), \\\n",
    "                StackingAveragedModels(base_models = (ENet, lasso, forest_regr), meta_model = ridge))\n",
    "X_train , X_test, y_train, y_test = train_test_split(train_selected_features, target, test_size=0.4, random_state=0)\n",
    "stacked_averaged_models.fit(X_train, y_train)\n",
    "stacked_train_pred = stacked_averaged_models.predict(X_test)\n",
    "print(\"Stacked Model R-squared --> \", metrics.r2_score(y_pred=stacked_train_pred, y_true=y_test))\n",
    "print('MSE of Stacked Model',metrics.mean_squared_error(y_test, stacked_train_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
