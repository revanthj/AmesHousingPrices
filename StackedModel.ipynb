{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=2)\n",
    "pd.set_option('precision', 2)\n",
    "np.set_printoptions(suppress=True)\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Size :  (1460, 80)\n",
      "Test Set Size :  (1459, 79)\n",
      "Train Features Size :  (1460, 79)\n",
      "Train Rows :  1460\n",
      "Test Rows :  1459\n"
     ]
    }
   ],
   "source": [
    "train_path = 'data/train.csv'\n",
    "test_path = 'data/test.csv'\n",
    "train_data = pd.read_csv(train_path, index_col='Id')\n",
    "test_data = pd.read_csv(test_path, index_col='Id')\n",
    "features = train_data.iloc[:,:-1]\n",
    "target = train_data.loc[:, ['SalePrice']]\n",
    "print('Train Set Size : ', train_data.shape)\n",
    "print('Test Set Size : ', test_data.shape)\n",
    "print('Train Features Size : ', features.shape)\n",
    "num_train_rows = train_data.shape[0]\n",
    "num_test_rows = test_data.shape[0]\n",
    "print('Train Rows : ', num_train_rows)\n",
    "print('Test Rows : ', num_test_rows)\n",
    "all_data = pd.concat((features, test_data)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness of SalePrice before Log Transform : 1.882876\n",
      "Kurtosis of SalePrice before Log Transform : 6.536282\n",
      "Skewness of SalePrice after Log Transform : 0.121335\n",
      "Kurtosis of SalePrice after Log Transform : 0.809532\n"
     ]
    }
   ],
   "source": [
    "# Analyze SalePrice\n",
    "print('Skewness of SalePrice before Log Transform : %f'% target.skew())\n",
    "print('Kurtosis of SalePrice before Log Transform : %f'% target.kurt())\n",
    "\n",
    "'''\n",
    "Skew = 1.882876 indicates positive skew with tail to the right.\n",
    "Kurt = 6.536282 indicates heavy tails i.e. more data on tails.\n",
    "'''\n",
    "\n",
    "#Apply Log transformation\n",
    "target['SalePrice'] = np.log(target['SalePrice'])\n",
    "print('Skewness of SalePrice after Log Transform : %f'% target.skew())\n",
    "print('Kurtosis of SalePrice after Log Transform : %f'% target.kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Missing Ratio\n",
      "PoolQC                99.66\n",
      "MiscFeature           96.40\n",
      "Alley                 93.22\n",
      "Fence                 80.44\n",
      "FireplaceQu           48.65\n",
      "LotFrontage           16.65\n",
      "GarageFinish           5.45\n",
      "GarageQual             5.45\n",
      "GarageCond             5.45\n",
      "GarageYrBlt            5.45\n",
      "GarageType             5.38\n",
      "BsmtExposure           2.81\n",
      "BsmtCond               2.81\n",
      "BsmtQual               2.77\n",
      "BsmtFinType2           2.74\n",
      "BsmtFinType1           2.71\n",
      "MasVnrType             0.82\n",
      "MasVnrArea             0.79\n",
      "MSZoning               0.14\n",
      "BsmtFullBath           0.07\n",
      "BsmtHalfBath           0.07\n",
      "Functional             0.07\n",
      "Utilities              0.07\n",
      "GarageArea             0.03\n",
      "GarageCars             0.03\n",
      "Electrical             0.03\n",
      "KitchenQual            0.03\n",
      "TotalBsmtSF            0.03\n",
      "BsmtUnfSF              0.03\n",
      "BsmtFinSF2             0.03\n",
      "BsmtFinSF1             0.03\n",
      "Exterior2nd            0.03\n",
      "Exterior1st            0.03\n",
      "SaleType               0.03\n",
      "Empty DataFrame\n",
      "Columns: [Missing Ratio]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Missing Data\n",
    "null_features = all_data.columns[all_data.isnull().any()]\n",
    "missing_ratio = (all_data[null_features].isnull().sum()/len(all_data)) * 100\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :missing_ratio})\n",
    "print(missing_data.sort_values(by='Missing Ratio',ascending=False))\n",
    "\n",
    "\n",
    "for col in ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu']:\n",
    "    all_data[col] = all_data[col].fillna('None')\n",
    "\n",
    "for col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'MasVnrType']:\n",
    "    all_data[col] = all_data[col].fillna('None')\n",
    "    \n",
    "for col in ['BsmtExposure', 'BsmtFinType2', 'BsmtQual', 'BsmtCond', 'BsmtFinType1']:\n",
    "    all_data[col] = all_data[col].fillna('None')\n",
    "\n",
    "'''\n",
    "No GarageYrBlt means no Garage. We can impute mean/median since it would \n",
    "incorrectly convey existence of Garage. same reasoning for MasVnrArea.\n",
    "'''\n",
    "for col in ['GarageYrBlt', 'MasVnrArea']:\n",
    "    all_data[col] = all_data[col].fillna(0)\n",
    "\n",
    "'''\n",
    "Group data by neighborhood & imputed null LotFrontage columns with median of\n",
    "grouped data.\n",
    "'''\n",
    "all_data['LotFrontage'] = all_data.groupby(['Neighborhood'])\\\n",
    "                    ['LotFrontage'].transform(lambda x : x.fillna(x.median()))\n",
    "    \n",
    "all_data['Electrical'] = \\\n",
    "    all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])\n",
    "    \n",
    "all_data['MSZoning'] = \\\n",
    "    all_data['MSZoning'].fillna(all_data['MSZoning'].mode()[0])\n",
    "    \n",
    "all_data['Utilities'] = all_data['Utilities'].fillna('ELO')\n",
    "\n",
    "all_data['Exterior1st'] = all_data['Exterior1st'].fillna('Other')\n",
    "\n",
    "all_data['Exterior2nd'] = all_data['Exterior2nd'].fillna('Other')\n",
    "\n",
    "all_data['SaleType'] = all_data['SaleType'].fillna('Oth')\n",
    "\n",
    "all_data['Functional'] = \\\n",
    "    all_data['Functional'].fillna(all_data['Functional'].mode()[0])\n",
    "\n",
    "all_data['KitchenQual'] = \\\n",
    "    all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])\n",
    "\n",
    "for col in ['BsmtFullBath', 'BsmtHalfBath', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'GarageCars', 'GarageArea']:\n",
    "    all_data[col] = all_data[col].fillna(0)\n",
    "    \n",
    "null_features = all_data.columns[all_data.isnull().any()]\n",
    "missing_ratio = (all_data[null_features].isnull().sum()/len(all_data)) * 100\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :missing_ratio})\n",
    "print(missing_data.sort_values(by='Missing Ratio',ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness of OverallQual before Log Transform : 0.197212\n",
      "Kurtosis of OverallQual before Log Transform : 0.067219\n",
      "Skewness of GarageCars before Log Transform : -0.219694\n",
      "Kurtosis of GarageCars before Log Transform : 0.236592\n",
      "Skewness of YearBuilt before Log Transform : -0.600114\n",
      "Kurtosis of YearBuilt before Log Transform : -0.511317\n",
      "Skewness of FullBath before Log Transform : 0.167692\n",
      "Kurtosis of FullBath before Log Transform : -0.538129\n",
      "Skewness of TotalBsmtSF before Log Transform : 1.157489\n",
      "Kurtosis of TotalBsmtSF before Log Transform : 9.122827\n",
      "Skewness of YearRemodAdd before Log Transform : -0.451252\n",
      "Kurtosis of YearRemodAdd before Log Transform : -1.346431\n",
      "Skewness of TotRmsAbvGrd before Log Transform : 0.758757\n",
      "Kurtosis of TotRmsAbvGrd before Log Transform : 1.169064\n",
      "Skewness of Fireplaces before Log Transform : 0.733872\n",
      "Kurtosis of Fireplaces before Log Transform : 0.076424\n",
      "Skewness of OpenPorchSF before Log Transform : 2.536417\n",
      "Kurtosis of OpenPorchSF before Log Transform : 10.937353\n",
      "Skewness of LotArea before Log Transform : 12.829025\n",
      "Kurtosis of LotArea before Log Transform : 264.952310\n",
      "Skewness of MasVnrArea before Log Transform : 2.614936\n",
      "Kurtosis of MasVnrArea before Log Transform : 9.336415\n",
      "Skewness of TotalBsmtSF after Log Transform : -0.424181\n",
      "Kurtosis of TotalBsmtSF after Log Transform : 1.712836\n",
      "Skewness of TotalBsmtSF after Log Transform : -0.742638\n",
      "Kurtosis of TotalBsmtSF after Log Transform : 2.775776\n",
      "Skewness of LotArea after Log Transform : -0.505542\n",
      "Kurtosis of LotArea after Log Transform : 3.754157\n",
      "Skewness of MasVnrArea after Log Transform : 0.242429\n",
      "Kurtosis of MasVnrArea after Log Transform : 5.717325\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "                    Numerical Features - Analysis\n",
    "Selected Features : \n",
    "    'OverallQual', 'GarageCars', 'YearBuilt','FullBath', 'TotalBsmtSF', \n",
    "    'YearRemodAdd', 'TotRmsAbvGrd', 'Fireplaces', 'OpenPorchSF', 'LotArea', \n",
    "    'MasVnrArea'\n",
    "'''\n",
    "print('Skewness of OverallQual before Log Transform : %f'% all_data['OverallQual'].skew())\n",
    "print('Kurtosis of OverallQual before Log Transform : %f'% all_data['OverallQual'].kurt())\n",
    "\n",
    "print('Skewness of GarageCars before Log Transform : %f'% all_data['GarageCars'].skew())\n",
    "print('Kurtosis of GarageCars before Log Transform : %f'% all_data['GarageCars'].kurt())\n",
    "\n",
    "print('Skewness of YearBuilt before Log Transform : %f'% all_data['YearBuilt'].skew())\n",
    "print('Kurtosis of YearBuilt before Log Transform : %f'% all_data['YearBuilt'].kurt())\n",
    "\n",
    "print('Skewness of FullBath before Log Transform : %f'% all_data['FullBath'].skew())\n",
    "print('Kurtosis of FullBath before Log Transform : %f'% all_data['FullBath'].kurt())\n",
    "\n",
    "print('Skewness of TotalBsmtSF before Log Transform : %f'% all_data['TotalBsmtSF'].skew())\n",
    "print('Kurtosis of TotalBsmtSF before Log Transform : %f'% all_data['TotalBsmtSF'].kurt())\n",
    "\n",
    "print('Skewness of YearRemodAdd before Log Transform : %f'% all_data['YearRemodAdd'].skew())\n",
    "print('Kurtosis of YearRemodAdd before Log Transform : %f'% all_data['YearRemodAdd'].kurt())\n",
    "\n",
    "print('Skewness of TotRmsAbvGrd before Log Transform : %f'% all_data['TotRmsAbvGrd'].skew())\n",
    "print('Kurtosis of TotRmsAbvGrd before Log Transform : %f'% all_data['TotRmsAbvGrd'].kurt())\n",
    "\n",
    "print('Skewness of Fireplaces before Log Transform : %f'% all_data['Fireplaces'].skew())\n",
    "print('Kurtosis of Fireplaces before Log Transform : %f'% all_data['Fireplaces'].kurt())\n",
    "\n",
    "print('Skewness of OpenPorchSF before Log Transform : %f'% all_data['OpenPorchSF'].skew())\n",
    "print('Kurtosis of OpenPorchSF before Log Transform : %f'% all_data['OpenPorchSF'].kurt())\n",
    "\n",
    "print('Skewness of LotArea before Log Transform : %f'% all_data['LotArea'].skew())\n",
    "print('Kurtosis of LotArea before Log Transform : %f'% all_data['LotArea'].kurt())\n",
    "\n",
    "print('Skewness of MasVnrArea before Log Transform : %f'% all_data['MasVnrArea'].skew())\n",
    "print('Kurtosis of MasVnrArea before Log Transform : %f'% all_data['MasVnrArea'].kurt())\n",
    "\n",
    "\n",
    "'''\n",
    "TotalBsmtSF, OpenPorchSF, LotArea, MasVnrArea\n",
    "These features has high Skewness & Kurtosis\n",
    "'''\n",
    "TotalBsmtSFMean = all_data['TotalBsmtSF'].mean()\n",
    "all_data.loc[all_data['TotalBsmtSF'] == 0, 'TotalBsmtSF'] = np.round(TotalBsmtSFMean).astype(int)\n",
    "all_data['TotalBsmtSF'] = np.log(all_data['TotalBsmtSF'])\n",
    "print('Skewness of TotalBsmtSF after Log Transform : %f'% all_data['TotalBsmtSF'].skew())\n",
    "print('Kurtosis of TotalBsmtSF after Log Transform : %f'% all_data['TotalBsmtSF'].kurt())\n",
    "\n",
    "OpenPorchSFMean = all_data['OpenPorchSF'].mean()\n",
    "all_data.loc[all_data['OpenPorchSF'] == 0, 'OpenPorchSF'] = np.round(OpenPorchSFMean).astype(int)\n",
    "all_data['TotalBsmtSF'] = np.log(all_data['TotalBsmtSF'])\n",
    "print('Skewness of TotalBsmtSF after Log Transform : %f'% all_data['TotalBsmtSF'].skew())\n",
    "print('Kurtosis of TotalBsmtSF after Log Transform : %f'% all_data['TotalBsmtSF'].kurt())\n",
    "\n",
    "all_data['LotArea'] = np.log(all_data['LotArea'])\n",
    "print('Skewness of LotArea after Log Transform : %f'% all_data['LotArea'].skew())\n",
    "print('Kurtosis of LotArea after Log Transform : %f'% all_data['LotArea'].kurt())\n",
    "\n",
    "MasVnrAreaMean = all_data['MasVnrArea'].mean()\n",
    "all_data.loc[all_data['MasVnrArea'] == 0, 'MasVnrArea'] = np.round(MasVnrAreaMean).astype(int)\n",
    "'''\n",
    "This is to handle 'NA' values in MasVnrArea column\n",
    "ms_df = all_data['MasVnrArea']\n",
    "print(np.any(np.isnan(ms_df)))\n",
    "If True, then find where NaNs exist\n",
    "print(np.where(np.isnan(ms_df)))\n",
    "''' \n",
    "all_data.loc[all_data['MasVnrArea'].isnull(), 'MasVnrArea'] = np.round(MasVnrAreaMean).astype(int)\n",
    "all_data['MasVnrArea'] = np.log(all_data['MasVnrArea'])\n",
    "print('Skewness of MasVnrArea after Log Transform : %f'% all_data['MasVnrArea'].skew())\n",
    "print('Kurtosis of MasVnrArea after Log Transform : %f'% all_data['MasVnrArea'].kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              SalePrice   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                  1.000\n",
      "Method:                 Least Squares   F-statistic:                 3.066e+05\n",
      "Date:                Sat, 07 Jul 2018   Prob (F-statistic):               0.00\n",
      "Time:                        20:38:39   Log-Likelihood:                 1268.8\n",
      "No. Observations:                1460   AIC:                            -2410.\n",
      "Df Residuals:                    1396   BIC:                            -2071.\n",
      "Df Model:                          64                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.0737      0.008      9.818      0.000       0.059       0.088\n",
      "x2             0.0507      0.004     12.885      0.000       0.043       0.058\n",
      "x3             0.0390      0.003     11.502      0.000       0.032       0.046\n",
      "x4             0.0023      0.000     10.771      0.000       0.002       0.003\n",
      "x5             0.0009      0.000      4.135      0.000       0.000       0.001\n",
      "x6          7.206e-05   9.89e-06      7.285      0.000    5.27e-05    9.15e-05\n",
      "x7          7.844e-05   2.83e-05      2.773      0.006    2.29e-05       0.000\n",
      "x8             0.6388      0.074      8.658      0.000       0.494       0.784\n",
      "x9             0.0003   8.46e-06     31.388      0.000       0.000       0.000\n",
      "x10            0.0227      0.008      3.023      0.003       0.008       0.037\n",
      "x11           -0.0582      0.015     -3.971      0.000      -0.087      -0.029\n",
      "x12            0.0225      0.005      4.164      0.000       0.012       0.033\n",
      "x13            0.0290      0.009      3.272      0.001       0.012       0.046\n",
      "x14          8.74e-05   3.01e-05      2.903      0.004    2.83e-05       0.000\n",
      "x15         8.557e-05   2.47e-05      3.466      0.001    3.71e-05       0.000\n",
      "x16            0.0002   5.11e-05      3.270      0.001    6.68e-05       0.000\n",
      "x17            0.0002   5.21e-05      4.729      0.000       0.000       0.000\n",
      "x18            0.0022      0.001      3.916      0.000       0.001       0.003\n",
      "x19           -0.0009      0.000     -3.115      0.002      -0.002      -0.000\n",
      "x20            0.4620      0.039     11.939      0.000       0.386       0.538\n",
      "x21            0.4073      0.044      9.305      0.000       0.321       0.493\n",
      "x22            0.3997      0.036     11.127      0.000       0.329       0.470\n",
      "x23            0.3521      0.036      9.749      0.000       0.281       0.423\n",
      "x24            0.0302      0.012      2.549      0.011       0.007       0.053\n",
      "x25            0.0624      0.015      4.049      0.000       0.032       0.093\n",
      "x26            0.1263      0.016      7.764      0.000       0.094       0.158\n",
      "x27           -0.0516      0.012     -4.313      0.000      -0.075      -0.028\n",
      "x28           -0.0745      0.028     -2.622      0.009      -0.130      -0.019\n",
      "x29           -0.0500      0.016     -3.166      0.002      -0.081      -0.019\n",
      "x30            0.0647      0.015      4.289      0.000       0.035       0.094\n",
      "x31            0.1069      0.022      4.772      0.000       0.063       0.151\n",
      "x32            0.0478      0.008      5.654      0.000       0.031       0.064\n",
      "x33            0.2439      0.107      2.281      0.023       0.034       0.454\n",
      "x34           -0.8464      0.077    -11.037      0.000      -0.997      -0.696\n",
      "x35            2.2193      0.137     16.243      0.000       1.951       2.487\n",
      "x36            2.4104      0.177     13.604      0.000       2.063       2.758\n",
      "x37            2.2622      0.173     13.111      0.000       1.924       2.601\n",
      "x38            2.2481      0.173     13.028      0.000       1.910       2.587\n",
      "x39            2.1757      0.143     15.254      0.000       1.896       2.455\n",
      "x40            2.2209      0.145     15.355      0.000       1.937       2.505\n",
      "x41            2.2930      0.143     16.055      0.000       2.013       2.573\n",
      "x42            0.0760      0.016      4.764      0.000       0.045       0.107\n",
      "x43            0.0825      0.028      2.967      0.003       0.028       0.137\n",
      "x44            0.0911      0.025      3.624      0.000       0.042       0.140\n",
      "x45            0.1224      0.026      4.723      0.000       0.072       0.173\n",
      "x46            0.2215      0.051      4.339      0.000       0.121       0.322\n",
      "x47            0.0391      0.013      2.901      0.004       0.013       0.066\n",
      "x48            0.0451      0.011      4.146      0.000       0.024       0.066\n",
      "x49            0.0328      0.013      2.440      0.015       0.006       0.059\n",
      "x50            0.1163      0.036      3.235      0.001       0.046       0.187\n",
      "x51            0.1868      0.042      4.405      0.000       0.104       0.270\n",
      "x52            0.2278      0.067      3.399      0.001       0.096       0.359\n",
      "x53            0.0278      0.007      3.914      0.000       0.014       0.042\n",
      "x54            0.0598      0.015      4.126      0.000       0.031       0.088\n",
      "x55            0.0566      0.014      4.126      0.000       0.030       0.084\n",
      "x56            0.1862      0.052      3.568      0.000       0.084       0.289\n",
      "x57            0.2436      0.047      5.152      0.000       0.151       0.336\n",
      "x58            0.2480      0.047      5.252      0.000       0.155       0.341\n",
      "x59            0.1315      0.052      2.510      0.012       0.029       0.234\n",
      "x60            0.2852      0.044      6.485      0.000       0.199       0.372\n",
      "x61            1.2477      0.338      3.689      0.000       0.584       1.911\n",
      "x62            0.1160      0.036      3.209      0.001       0.045       0.187\n",
      "x63            0.1180      0.015      7.877      0.000       0.089       0.147\n",
      "x64            0.0654      0.010      6.720      0.000       0.046       0.085\n",
      "==============================================================================\n",
      "Omnibus:                      368.552   Durbin-Watson:                   1.917\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4780.786\n",
      "Skew:                          -0.798   Prob(JB):                         0.00\n",
      "Kurtosis:                      11.720   Cond. No.                     6.04e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 6.04e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "['LotArea' 'OverallQual' 'OverallCond' 'YearBuilt' 'YearRemodAdd'\n",
      " 'BsmtFinSF1' 'BsmtFinSF2' 'TotalBsmtSF' 'GrLivArea' 'BsmtFullBath'\n",
      " 'KitchenAbvGr' 'Fireplaces' 'GarageCars' 'GarageArea' 'WoodDeckSF'\n",
      " 'EnclosedPorch' 'ScreenPorch' 'PoolArea' 'YrSold' 'MSZoning_FV'\n",
      " 'MSZoning_RH' 'MSZoning_RL' 'MSZoning_RM' 'LotConfig_CulDSac'\n",
      " 'Neighborhood_BrkSide' 'Neighborhood_Crawfor' 'Neighborhood_Edwards'\n",
      " 'Neighborhood_MeadowV' 'Neighborhood_Mitchel' 'Neighborhood_NridgHt'\n",
      " 'Neighborhood_StoneBr' 'Condition1_Norm' 'Condition2_PosA'\n",
      " 'Condition2_PosN' 'RoofMatl_CompShg' 'RoofMatl_Membran' 'RoofMatl_Metal'\n",
      " 'RoofMatl_Roll' 'RoofMatl_Tar&Grv' 'RoofMatl_WdShake' 'RoofMatl_WdShngl'\n",
      " 'Exterior1st_BrkFace' 'Foundation_BrkTil' 'Foundation_CBlock'\n",
      " 'Foundation_PConc' 'Foundation_Stone' 'BsmtQual_Ex' 'BsmtExposure_Gd'\n",
      " 'BsmtFinType2_Unf' 'Heating_GasA' 'Heating_GasW' 'Heating_Wall'\n",
      " 'HeatingQC_Ex' 'CentralAir_Y' 'KitchenQual_Ex' 'Functional_Maj1'\n",
      " 'Functional_Min1' 'Functional_Min2' 'Functional_Mod' 'Functional_Typ'\n",
      " 'PoolQC_None' 'SaleType_ConLD' 'SaleType_New' 'SaleCondition_Normal']\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "\n",
    "significance = 0.03\n",
    "all_data = pd.get_dummies(all_data)\n",
    "train_data_features = all_data[:num_train_rows]\n",
    "test_data_features = all_data[num_train_rows:]\n",
    "train_data_features_ones = np.append(arr=np.ones((1460,1)).astype(int), values=train_data_features, axis=1)\n",
    "cols = train_data_features.columns.values\n",
    "cols = np.insert(cols, 0, 'intercept')\n",
    "\n",
    "def backwardElimination(cols, train_num_features_ones):\n",
    "    for i in range (0, train_num_features_ones.shape[1]):\n",
    "        regressor_OLS = sm.OLS(endog=target, exog=train_num_features_ones).fit()\n",
    "        maxPVal = max(regressor_OLS.pvalues)\n",
    "        if maxPVal > significance:\n",
    "            for j in range(0, train_num_features_ones.shape[1]):\n",
    "                if (regressor_OLS.pvalues[j].astype(float) == maxPVal):\n",
    "                    train_num_features_ones = np.delete(train_num_features_ones, j, 1)\n",
    "                    cols = np.delete(cols, j)\n",
    "    print(regressor_OLS.summary())\n",
    "    return cols, train_num_features_ones\n",
    "\n",
    "cols, train_num_features_ones_df = backwardElimination(cols, train_data_features_ones)\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2919, 64)\n",
      "False\n",
      "(array([], dtype=int64), array([], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "selected_features = \\\n",
    "all_data.loc[:,['LotArea' ,'OverallQual' ,'OverallCond' ,'YearBuilt' ,\n",
    "'YearRemodAdd' ,'BsmtFinSF1' ,'BsmtFinSF2' ,'TotalBsmtSF' ,'GrLivArea' ,\n",
    "'BsmtFullBath' ,'KitchenAbvGr' ,'Fireplaces' ,'GarageCars' ,'GarageArea' ,\n",
    "'WoodDeckSF' ,'EnclosedPorch' ,'ScreenPorch' ,'PoolArea' ,'YrSold' ,'MSZoning_FV' ,\n",
    "'MSZoning_RH' ,'MSZoning_RL' ,'MSZoning_RM' ,'LotConfig_CulDSac' ,\n",
    "'Neighborhood_BrkSide' ,'Neighborhood_Crawfor' ,'Neighborhood_Edwards' ,\n",
    "'Neighborhood_MeadowV' ,'Neighborhood_Mitchel' ,'Neighborhood_NridgHt' ,\n",
    "'Neighborhood_StoneBr' ,'Condition1_Norm' ,'Condition2_PosA' ,'Condition2_PosN' ,\n",
    "'RoofMatl_CompShg' ,'RoofMatl_Membran' ,'RoofMatl_Metal' ,'RoofMatl_Roll' ,\n",
    "'RoofMatl_Tar&Grv' ,'RoofMatl_WdShake' ,'RoofMatl_WdShngl' ,'Exterior1st_BrkFace' ,\n",
    "'Foundation_BrkTil' ,'Foundation_CBlock' ,'Foundation_PConc' ,'Foundation_Stone' ,\n",
    "'BsmtQual_Ex' ,'BsmtExposure_Gd' ,'BsmtFinType2_Unf' ,'Heating_GasA' ,'Heating_GasW' ,\n",
    "'Heating_Wall' ,'HeatingQC_Ex' ,'CentralAir_Y' ,'KitchenQual_Ex' ,'Functional_Maj1' ,\n",
    "'Functional_Min1' ,'Functional_Min2' ,'Functional_Mod' ,'Functional_Typ' ,'PoolQC_None' ,\n",
    "'SaleType_ConLD' ,'SaleType_New' ,'SaleCondition_Normal']]\n",
    "\n",
    "print(selected_features.shape)\n",
    "\n",
    "# check whether there are any NaNs in the dataframe\n",
    "print(np.any(np.isnan(selected_features)))\n",
    "\n",
    "#If True, then find where NaNs exist\n",
    "print(np.where(np.isnan(selected_features)))\n",
    "\n",
    "train_selected_features = selected_features[:num_train_rows]\n",
    "test_selected_features = selected_features[num_train_rows:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy -->  82.86856255173419\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Establish a basline model - Linear Regression\n",
    "Baseline Accuracy - 82.87\n",
    "'''\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train , X_test, y_train, y_test = train_test_split(train_selected_features, target, test_size=0.4, random_state=0)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "y_train_predict = regressor.predict(X_test)\n",
    "print(\"Accuracy --> \", regressor.score(X_test, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy -->  86.03848907931788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Implement LASSO Regression with K-Fold\n",
    "Lasso 5-fold Accuracy -->  86.03\n",
    "'''\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import KFold, cross_val_predict, cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "#lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=0))\n",
    "#scores = cross_val_score(lasso, train_selected_features, target, cv=kf)\n",
    "#predictions = cross_val_predict(lasso, train_selected_features, target, cv=kf)\n",
    "#print(\"Lasso 5-fold Accuracy --> \", metrics.r2_score(y_pred=predictions, y_true=target))\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "lasso = make_pipeline(RobustScaler(), LassoCV(alphas=[0.002], random_state=0, cv=kf))\n",
    "lasso.fit(X_train, y_train)\n",
    "print(\"Accuracy --> \", lasso.score(X_test, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy -->  86.2492416142501\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Implement Ridge Regression with K-Fold\n",
    "KernelRidge 5-fold Accuracy -->  86.24\n",
    "'''\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import KFold, cross_val_predict, cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "#ridge = make_pipeline(RobustScaler(), Ridge(alpha =0.8, random_state=0))\n",
    "#kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "#predictions = cross_val_predict(ridge, train_selected_features, target, cv=kf)\n",
    "#print(\"KernelRidge 5-fold Accuracy --> \", metrics.r2_score(y_pred=predictions, y_true=target))\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "ridge = make_pipeline(RobustScaler(), RidgeCV(alphas=[2.5], cv=kf))\n",
    "ridge.fit(X_train, y_train)\n",
    "print(\"Accuracy --> \", ridge.score(X_test, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy -->  86.16665216650719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Implement ElasticNet Regression with K-Fold\n",
    "ElasticNet 5-fold Accuracy -->  86.17\n",
    "'''\n",
    "from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import KFold, cross_val_predict, cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "#ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.3, random_state=0))\n",
    "#kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "#predictions = cross_val_predict(ENet, train_selected_features, target, cv=kf)\n",
    "#print(\"ElasticNet 5-fold Accuracy --> \", metrics.r2_score(y_pred=predictions, y_true=target))\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "ENet = make_pipeline(RobustScaler(), ElasticNetCV(alphas=[0.003], cv=kf, random_state=0))\n",
    "ENet.fit(X_train, y_train)\n",
    "print(\"Accuracy --> \", ENet.score(X_test, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Random Forest Accuracy -->  88.74370937589907\n",
    "'''\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_regr = RandomForestRegressor(random_state=0, n_estimators=70,\n",
    "                        min_samples_split=2, min_samples_leaf=1, max_features='sqrt',\n",
    "                        max_depth=10, bootstrap=False)\n",
    "forest_regr.fit(X_train, y_train)\n",
    "print(\"Random Forest Accuracy --> \", forest_regr.score(X_test, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Simple Stacking of 4 models\n",
    "'''\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "class AverageModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy -->  86.38102459017608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Averaged 5-fold Accuracy --> 86.38\n",
    "'''\n",
    "#average_models = make_pipeline(RobustScaler(), AverageModels(models = (ENet, ridge, lasso)))\n",
    "#kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "#predictions = cross_val_predict(average_models, train_selected_features, target, cv=kf)\n",
    "#print(\"Averaged 5-fold Accuracy --> \", metrics.r2_score(y_pred=predictions, y_true=target))\n",
    "\n",
    "average_models = make_pipeline(RobustScaler(), AverageModels(models = (ENet, ridge, lasso, forest_regr)))\n",
    "average_models.fit(X_train, y_train)\n",
    "print(\"Accuracy --> \", average_models.score(X_test, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=0)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y.iloc[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred.flatten()\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked 5-fold Accuracy -->  0.8629723279049879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "stacked_averaged_models = make_pipeline(RobustScaler(), \\\n",
    "                StackingAveragedModels(base_models = (ENet, lasso, forest_regr), meta_model = ridge))\n",
    "X_train , X_test, y_train, y_test = train_test_split(train_selected_features, target, test_size=0.4, random_state=0)\n",
    "stacked_averaged_models.fit(X_train, y_train)\n",
    "stacked_train_pred = stacked_averaged_models.predict(X_test)\n",
    "print(\"Stacked 5-fold Accuracy --> \", metrics.r2_score(y_pred=stacked_train_pred, y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "LinearRegression : 0.16532\n",
    "lassocv : 0.12517\n",
    "ridgecv : 0.12809\n",
    "elasticnet : 0.12463\n",
    "average : 0.12445 without Random Forest\n",
    "average : 0.12504 with Random Forest\n",
    "stacked : 0.12435\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
