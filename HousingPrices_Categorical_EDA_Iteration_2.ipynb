{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=2)\n",
    "pd.set_option('precision', 2)\n",
    "np.set_printoptions(suppress=True)\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_path = '/Users/rjanaki/DataSets/ML-PredictHousingPrices/train.csv'\n",
    "train_data = pd.read_csv(input_path, index_col='Id')\n",
    "features = train_data.iloc[:,:-1]\n",
    "target = train_data.loc[:, ['SalePrice']]\n",
    "print(train_data.shape)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0195171690cb47b6361f25a3587970c9c2ac633c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Missing Data\n",
    "null_features = train_data.columns[train_data.isnull().any()]\n",
    "missing_ratio = (train_data[null_features].isnull().sum()/len(train_data)) * 100\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :missing_ratio})\n",
    "print(missing_data.sort_values(by='Missing Ratio',ascending=False))\n",
    "\n",
    "\n",
    "for col in ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu']:\n",
    "    train_data[col] = train_data[col].fillna('None')\n",
    "\n",
    "for col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'MasVnrType']:\n",
    "    train_data[col] = train_data[col].fillna('None')\n",
    "    \n",
    "for col in ['BsmtExposure', 'BsmtFinType2', 'BsmtQual', 'BsmtCond', 'BsmtFinType1']:\n",
    "    train_data[col] = train_data[col].fillna('None')\n",
    "\n",
    "'''\n",
    "No GarageYrBlt means no Garage. We can impute mean/median since it would \n",
    "incorrectly convey existence of Garage. same reasoning for MasVnrArea.\n",
    "'''\n",
    "for col in ['GarageYrBlt', 'MasVnrArea']:\n",
    "    train_data[col] = train_data[col].fillna(0)\n",
    "\n",
    "'''\n",
    "Group data by neighborhood & imputed null LotFrontage columns with median of\n",
    "grouped data.\n",
    "'''\n",
    "train_data['LotFrontage'] = train_data.groupby(['Neighborhood'])\\\n",
    "                    ['LotFrontage'].transform(lambda x : x.fillna(x.median()))\n",
    "    \n",
    "train_data['Electrical'] = \\\n",
    "    train_data['Electrical'].fillna(train_data['Electrical'].mode()[0])\n",
    "    \n",
    "null_features = train_data.columns[train_data.isnull().any()]\n",
    "missing_ratio = (train_data[null_features].isnull().sum()/len(train_data)) * 100\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :missing_ratio})\n",
    "print(missing_data.sort_values(by='Missing Ratio',ascending=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "02bf3d4e03782b0e87dc8627a22bd0df7971e3ab",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Categorical Variable Analysis\n",
    "cat_features = train_data.select_dtypes(exclude=np.number)\n",
    "cat_feature_nms = cat_features.columns\n",
    "print('Number of cat features : ' + str(cat_feature_nms.size))\n",
    "\n",
    "\n",
    "def anova(data):\n",
    "    anvova_sig_values = pd.DataFrame()\n",
    "    anvova_sig_values['feature'] = cat_feature_nms\n",
    "    pvals = []\n",
    "    for col in cat_feature_nms:\n",
    "        col_group_vals = []\n",
    "        for cls in data[col].unique():\n",
    "            s = data[data[col] == cls]['SalePrice'].values\n",
    "            col_group_vals.append(s)\n",
    "        pval = stats.f_oneway(*col_group_vals)[1]\n",
    "        pvals.append(pval)\n",
    "    anvova_sig_values['pval'] = pvals\n",
    "    return anvova_sig_values.sort_values('pval')\n",
    "\n",
    "a = anova(train_data)\n",
    "a['disparity'] = np.log(1./a['pval'].values)\n",
    "plt.subplots(figsize=(15,10))\n",
    "sns.barplot(data=a, x='feature', y='disparity')\n",
    "x=plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c421deb05f88e4be5d494fb92ba9913a2f65f962",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Select first 20 categorical columns with most correlation with SalePrice\n",
    "sig_cat_columns = a['feature']\n",
    "print('Significant columns : ' + str(sig_cat_columns.values))\n",
    "\n",
    "# Correlation between Significant categorical variables\n",
    "from itertools import combinations\n",
    "sig_cat_columns_combo = [combo for combo in combinations(sig_cat_columns, 2)]\n",
    "\n",
    "def isCorrelated(p):\n",
    "    if p < 0.05:\n",
    "        return 'YES'\n",
    "    else:\n",
    "        return 'NOT'\n",
    "\n",
    "p_value_table = pd.DataFrame(index = sig_cat_columns, columns = sig_cat_columns)\n",
    "from scipy.stats import chi2_contingency\n",
    "from pandas import crosstab\n",
    "for (col1, col2) in sig_cat_columns_combo:\n",
    "    crosstable = crosstab(train_data[col1], train_data[col2])\n",
    "    chi2, p, dof, expected = chi2_contingency(crosstable)\n",
    "    p_value_table[col1][col2] = isCorrelated(p)\n",
    "    \n",
    "p_value_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b4e2e9f59272d61e5482a5a9aa98a055978293fd",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Below are features that are not correlated to Neighborhood.\n",
    "Neighborhood, PoolQC, Heating, MiscFeature, Condition2.\n",
    "Lets check if they are coorelated to one another.\n",
    "'''\n",
    "sig_cat_columns_short = ['Neighborhood', 'PoolQC', 'Heating', 'MiscFeature', 'Condition2']\n",
    "\n",
    "sig_cat_columns_combo_short = [combo for combo in combinations(sig_cat_columns_short, 2)]\n",
    "\n",
    "p_value_table_short = pd.DataFrame(index = sig_cat_columns_short, columns = sig_cat_columns_short)\n",
    "\n",
    "for (col1, col2) in sig_cat_columns_combo_short:\n",
    "    crosstable = crosstab(train_data[col1], train_data[col2])\n",
    "    chi2, p, dof, expected = chi2_contingency(crosstable)\n",
    "    p_value_table_short[col1][col2] = isCorrelated(p)\n",
    "    \n",
    "print(p_value_table_short)\n",
    "\n",
    "'''\n",
    "MiscFeature is correlated to PoolQC.\n",
    "Condition2 is correlated to MiscFeature.\n",
    "So, lets remove MiscFeature from Model.\n",
    "Final categorical columns are Neighborhood, PoolQC, Heating, Condition2.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1d0049822da5a90bdd1d03989a14eafd2df4ff90",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9f7c0f4a0b28cab01409edd944ff6a5c206a4eb6",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "197953dde9c2859a2e0f4dc60b1aacd0b3bb8e34",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c83777036e60ff2bec4f78085ab16271c08d18e0",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3efa92f8cee1b699b57572835cdb53d2fc59db4c",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
