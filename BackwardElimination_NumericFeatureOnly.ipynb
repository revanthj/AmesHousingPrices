{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=2)\n",
    "pd.set_option('precision', 2)\n",
    "np.set_printoptions(suppress=True)\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Size :  (1460, 80)\n",
      "Test Set Size :  (1459, 79)\n",
      "Train Features Size :  (1460, 79)\n",
      "Train Rows :  1460\n",
      "Test Rows :  1459\n"
     ]
    }
   ],
   "source": [
    "#1. Load training and test datasets\n",
    "train_path = 'data/train.csv'\n",
    "test_path = 'data/test.csv'\n",
    "train_data = pd.read_csv(train_path, index_col='Id')\n",
    "test_data = pd.read_csv(test_path, index_col='Id')\n",
    "\n",
    "#1a. Seperate features and target from training dataset.\n",
    "features = train_data.iloc[:,:-1]\n",
    "target = train_data.loc[:, ['SalePrice']]\n",
    "print('Train Set Size : ', train_data.shape)\n",
    "print('Test Set Size : ', test_data.shape)\n",
    "print('Train Features Size : ', features.shape)\n",
    "num_train_rows = train_data.shape[0]\n",
    "num_test_rows = test_data.shape[0]\n",
    "print('Train Rows : ', num_train_rows)\n",
    "print('Test Rows : ', num_test_rows)\n",
    "\n",
    "#1b. Merge training and test datasets to cover all \n",
    "#encodings for categorical features\n",
    "all_data = pd.concat((features, test_data)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness of SalePrice before Log Transform : 1.882876\n",
      "Kurtosis of SalePrice before Log Transform : 6.536282\n",
      "Skewness of SalePrice after Log Transform : 0.121335\n",
      "Kurtosis of SalePrice after Log Transform : 0.809532\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "2. In Numerical feature analysis, I found that SalPrice is NOT NORMALLY DISTRIBUTED.\n",
    "So, apply LOG TRANSFORMATION to bring SalePrice closer to Normal Distribution.\n",
    "'''\n",
    "print('Skewness of SalePrice before Log Transform : %f'% target.skew())\n",
    "print('Kurtosis of SalePrice before Log Transform : %f'% target.kurt())\n",
    "\n",
    "'''\n",
    "Skew = 1.882876 indicates positive skew with tail to the right.\n",
    "Kurt = 6.536282 indicates heavy tails i.e. more data on tails.\n",
    "'''\n",
    "\n",
    "#Apply Log transformation\n",
    "target['SalePrice'] = np.log(target['SalePrice'])\n",
    "print('Skewness of SalePrice after Log Transform : %f'% target.skew())\n",
    "print('Kurtosis of SalePrice after Log Transform : %f'% target.kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Missing Ratio\n",
      "PoolQC                99.66\n",
      "MiscFeature           96.40\n",
      "Alley                 93.22\n",
      "Fence                 80.44\n",
      "FireplaceQu           48.65\n",
      "LotFrontage           16.65\n",
      "GarageFinish           5.45\n",
      "GarageQual             5.45\n",
      "GarageCond             5.45\n",
      "GarageYrBlt            5.45\n",
      "GarageType             5.38\n",
      "BsmtExposure           2.81\n",
      "BsmtCond               2.81\n",
      "BsmtQual               2.77\n",
      "BsmtFinType2           2.74\n",
      "BsmtFinType1           2.71\n",
      "MasVnrType             0.82\n",
      "MasVnrArea             0.79\n",
      "MSZoning               0.14\n",
      "BsmtFullBath           0.07\n",
      "BsmtHalfBath           0.07\n",
      "Functional             0.07\n",
      "Utilities              0.07\n",
      "GarageArea             0.03\n",
      "GarageCars             0.03\n",
      "Electrical             0.03\n",
      "KitchenQual            0.03\n",
      "TotalBsmtSF            0.03\n",
      "BsmtUnfSF              0.03\n",
      "BsmtFinSF2             0.03\n",
      "BsmtFinSF1             0.03\n",
      "Exterior2nd            0.03\n",
      "Exterior1st            0.03\n",
      "SaleType               0.03\n",
      "Empty DataFrame\n",
      "Columns: [Missing Ratio]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#3. Missing Data\n",
    "null_features = all_data.columns[all_data.isnull().any()]\n",
    "missing_ratio = (all_data[null_features].isnull().sum()/len(all_data)) * 100\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :missing_ratio})\n",
    "print(missing_data.sort_values(by='Missing Ratio',ascending=False))\n",
    "\n",
    "\n",
    "for col in ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu']:\n",
    "    all_data[col] = all_data[col].fillna('None')\n",
    "\n",
    "for col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'MasVnrType']:\n",
    "    all_data[col] = all_data[col].fillna('None')\n",
    "    \n",
    "for col in ['BsmtExposure', 'BsmtFinType2', 'BsmtQual', 'BsmtCond', 'BsmtFinType1']:\n",
    "    all_data[col] = all_data[col].fillna('None')\n",
    "\n",
    "'''\n",
    "No GarageYrBlt means no Garage. I can impute mean/median since it would \n",
    "incorrectly convey existence of Garage. same reasoning for MasVnrArea.\n",
    "'''\n",
    "for col in ['GarageYrBlt', 'MasVnrArea']:\n",
    "    all_data[col] = all_data[col].fillna(0)\n",
    "\n",
    "'''\n",
    "Group data by neighborhood & imputed null LotFrontage columns with median of\n",
    "grouped data.\n",
    "'''\n",
    "all_data['LotFrontage'] = all_data.groupby(['Neighborhood'])\\\n",
    "                    ['LotFrontage'].transform(lambda x : x.fillna(x.median()))\n",
    "    \n",
    "all_data['Electrical'] = \\\n",
    "    all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])\n",
    "    \n",
    "all_data['MSZoning'] = \\\n",
    "    all_data['MSZoning'].fillna(all_data['MSZoning'].mode()[0])\n",
    "    \n",
    "all_data['Utilities'] = all_data['Utilities'].fillna('ELO')\n",
    "\n",
    "all_data['Exterior1st'] = all_data['Exterior1st'].fillna('Other')\n",
    "\n",
    "all_data['Exterior2nd'] = all_data['Exterior2nd'].fillna('Other')\n",
    "\n",
    "all_data['SaleType'] = all_data['SaleType'].fillna('Oth')\n",
    "\n",
    "all_data['Functional'] = \\\n",
    "    all_data['Functional'].fillna(all_data['Functional'].mode()[0])\n",
    "\n",
    "all_data['KitchenQual'] = \\\n",
    "    all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])\n",
    "\n",
    "for col in ['BsmtFullBath', 'BsmtHalfBath', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'GarageCars', 'GarageArea']:\n",
    "    all_data[col] = all_data[col].fillna(0)\n",
    "    \n",
    "null_features = all_data.columns[all_data.isnull().any()]\n",
    "missing_ratio = (all_data[null_features].isnull().sum()/len(all_data)) * 100\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :missing_ratio})\n",
    "print(missing_data.sort_values(by='Missing Ratio',ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              SalePrice   R-squared:                       0.867\n",
      "Model:                            OLS   Adj. R-squared:                  0.865\n",
      "Method:                 Least Squares   F-statistic:                     470.3\n",
      "Date:                Wed, 19 Dec 2018   Prob (F-statistic):               0.00\n",
      "Time:                        19:11:09   Log-Likelihood:                 743.10\n",
      "No. Observations:                1460   AIC:                            -1444.\n",
      "Df Residuals:                    1439   BIC:                            -1333.\n",
      "Df Model:                          20                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         16.4857      5.865      2.811      0.005       4.982      27.990\n",
      "x1            -0.0006      0.000     -6.080      0.000      -0.001      -0.000\n",
      "x2          1.872e-06   4.22e-07      4.438      0.000    1.04e-06     2.7e-06\n",
      "x3             0.0836      0.005     17.140      0.000       0.074       0.093\n",
      "x4             0.0498      0.004     11.753      0.000       0.041       0.058\n",
      "x5             0.0030      0.000     12.724      0.000       0.003       0.004\n",
      "x6             0.0011      0.000      4.021      0.000       0.001       0.002\n",
      "x7           2.68e-05   1.28e-05      2.099      0.036    1.75e-06    5.18e-05\n",
      "x8          6.033e-05   1.32e-05      4.574      0.000    3.45e-05    8.62e-05\n",
      "x9             0.0002   1.73e-05     11.043      0.000       0.000       0.000\n",
      "x10            0.0606      0.010      6.001      0.000       0.041       0.080\n",
      "x11            0.0301      0.011      2.786      0.005       0.009       0.051\n",
      "x12           -0.0485      0.021     -2.303      0.021      -0.090      -0.007\n",
      "x13            0.0141      0.005      3.069      0.002       0.005       0.023\n",
      "x14            0.0477      0.007      6.602      0.000       0.034       0.062\n",
      "x15            0.0744      0.007     10.521      0.000       0.060       0.088\n",
      "x16            0.0001   3.33e-05      3.779      0.000    6.05e-05       0.000\n",
      "x17            0.0002   7.06e-05      2.317      0.021    2.51e-05       0.000\n",
      "x18            0.0004   7.19e-05      5.146      0.000       0.000       0.001\n",
      "x19           -0.0004   9.87e-05     -4.010      0.000      -0.001      -0.000\n",
      "x20           -0.0070      0.003     -2.397      0.017      -0.013      -0.001\n",
      "==============================================================================\n",
      "Omnibus:                     1043.613   Durbin-Watson:                   1.974\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            56474.226\n",
      "Skew:                          -2.730   Prob(JB):                         0.00\n",
      "Kurtosis:                      32.976   Cond. No.                     2.26e+07\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.26e+07. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "['intercept' 'MSSubClass' 'LotArea' 'OverallQual' 'OverallCond'\n",
      " 'YearBuilt' 'YearRemodAdd' 'BsmtFinSF1' 'TotalBsmtSF' 'GrLivArea'\n",
      " 'BsmtFullBath' 'FullBath' 'KitchenAbvGr' 'TotRmsAbvGrd' 'Fireplaces'\n",
      " 'GarageCars' 'WoodDeckSF' 'EnclosedPorch' 'ScreenPorch' 'PoolArea'\n",
      " 'YrSold']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "            4. Try Backward Elimination with significance = 0.05\n",
    "               for Numeric features only.\n",
    "'''\n",
    "\n",
    "num_features = all_data.select_dtypes(include=np.number)\n",
    "\n",
    "import statsmodels.formula.api as sm\n",
    "\n",
    "train_num_features = num_features[:num_train_rows]\n",
    "test_num_features = num_features[num_train_rows:]\n",
    "\n",
    "significance = 0.05\n",
    "train_num_features_ones = np.append(arr=np.ones((1460,1)).astype(int), values=train_num_features, axis=1)\n",
    "\n",
    "train_path = 'data/train.csv'\n",
    "train_dt = pd.read_csv(train_path)\n",
    "cols = num_features.columns.values\n",
    "cols = np.insert(cols, 0, 'intercept')\n",
    "\n",
    "def backwardElimination(cols, train_num_features_ones):\n",
    "    for i in range (0, train_num_features_ones.shape[1]):\n",
    "        regressor_OLS = sm.OLS(endog=target, exog=train_num_features_ones).fit()\n",
    "        maxPVal = max(regressor_OLS.pvalues)\n",
    "        if maxPVal > significance:\n",
    "            for j in range(0, train_num_features_ones.shape[1]):\n",
    "                if (regressor_OLS.pvalues[j].astype(float) == maxPVal):\n",
    "                    train_num_features_ones = np.delete(train_num_features_ones, j, 1)\n",
    "                    cols = np.delete(cols, j)\n",
    "    print(regressor_OLS.summary())\n",
    "    return cols, train_num_features_ones\n",
    "\n",
    "cols, train_num_features_ones_df = backwardElimination(cols, train_num_features_ones)\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 0.09211915116363405\n",
      "MSE 0.02568874200980863\n",
      "R-squared -->  82.98979246558213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\revan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nSummary:\\n    we found that by including significant Numeric features only, \\n    MSE decreased by 18.2%\\n    MSE Numeric Features Only : 0.02568874200980863\\n    MSE All Features : 0.0314192011431451 (refer BackwardFeatureElimination.ipynb)\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "            5. RIDGE Model with selected parameters\n",
    "'''\n",
    "final_num_features = all_data.loc[:,['MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', \n",
    "                               'BsmtFinSF1', 'TotalBsmtSF', 'GrLivArea', 'BsmtFullBath', 'FullBath', 'KitchenAbvGr', \n",
    "                               'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'WoodDeckSF', 'EnclosedPorch', \n",
    "                               'ScreenPorch', 'PoolArea', 'YrSold']]\n",
    "final_num_features.insert(0, 'intercept', np.ones((2919,1)))\n",
    "final_train_num_features = final_num_features[:num_train_rows]\n",
    "final_test_num_features = final_num_features[num_train_rows:]\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train , X_test, y_train, y_test = train_test_split(final_train_num_features, target, test_size=0.4, random_state=0)\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "regressor = Ridge(alpha=0.05, normalize=True)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "from sklearn import metrics\n",
    "y_train_predict = regressor.predict(X_test)\n",
    "print('MAE',metrics.mean_absolute_error(y_test, y_train_predict))\n",
    "print('MSE',metrics.mean_squared_error(y_test, y_train_predict))\n",
    "print(\"R-squared --> \", regressor.score(X_test, y_test)*100)\n",
    "\n",
    "'''\n",
    "Summary:\n",
    "    we found that by including significant Numeric features only, \n",
    "    MSE decreased by 18.2%\n",
    "    MSE Numeric Features Only : 0.02568874200980863\n",
    "    MSE All Features : 0.0314192011431451 (refer BackwardFeatureElimination.ipynb)\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
